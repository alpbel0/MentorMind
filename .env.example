# =====================================================
# MentorMind - Environment Variables
# =====================================================
# Bu dosya proje icin tum environment degiskenlerini icerir
# Kopyasini olusturmak icin: cp .env.example .env

# =====================================================
# API Keys (REQUIRED)
# =====================================================
# Anthropic API Key - Claude modelleri icin
# Almak icin: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-your-key-here

# OpenAI API Key - GPT modelleri ve embeddings icin
# Almak icin: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-key-here

# OpenRouter API Key - K Models unified access
# Almak icin: https://openrouter.ai/keys
OPENROUTER_API_KEY=sk-or-v1-your-key-here

# Google API Key - Gemini modelleri icin
# Almak icin: https://aistudio.google.com/app/apikey
GOOGLE_API_KEY=your-google-key-here

# =====================================================
# PostgreSQL Database (REQUIRED)
# =====================================================
# Database connection URL
DATABASE_URL=postgresql://mentormind:mentormind_password@postgres:5432/mentormind

# PostgreSQL credentials
POSTGRES_USER=mentormind
POSTGRES_PASSWORD=mentormind_password
POSTGRES_DB=mentormind
POSTGRES_HOST=postgres
POSTGRES_PORT=5432

# =====================================================
# ChromaDB Vector Database (REQUIRED)
# =====================================================
# ChromaDB server configuration (HTTP client - persist directory managed by Docker volume)
CHROMA_HOST=chromadb
CHROMA_PORT=8000
# CHROMA_PERSIST_DIR is NOT used by HTTP client (persist handled by Docker volume at /data)
CHROMA_PERSIST_DIR=/chroma_data
CHROMA_COLLECTION_NAME=evaluation_memory

# =====================================================
# Application Settings
# =====================================================
# Environment: development, production
ENVIRONMENT=development

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# API Server
API_HOST=0.0.0.0
API_PORT=8000
RELOAD=true  # Auto-reload on code changes (development only)

# =====================================================
# Judge Configuration
# =====================================================
# Judge timeout in seconds
JUDGE_TIMEOUT_SECONDS=60

# =====================================================
# LLM Model Configuration
# =====================================================
# Question Generation Model (Anthropic Claude Haiku 4.5)
# Faster and more cost-effective for question generation
CLAUDE_QUESTION_MODEL=claude-haiku-4-5-20251001

# Legacy Claude Model (deprecated, use CLAUDE_QUESTION_MODEL)
CLAUDE_MODEL=claude-sonnet-4-20250514

# Judge Model (OpenAI GPT-4o)
JUDGE_MODEL=gpt-4o

# K Models (6 models via OpenRouter)
K_MODELS=mistralai/mistral-nemo,qwen/qwen-2.5-7b-instruct,deepseek/deepseek-chat,google/gemini-2.0-flash-001,openai/gpt-4o-mini,openai/gpt-3.5-turbo

# Embeddings Model (OpenAI)
EMBEDDING_MODEL=text-embedding-3-small

# =====================================================
# Development Settings
# =====================================================
# Enable debug mode
DEBUG=false

# Enable CORS (for future frontend)
CORS_ORIGINS=http://localhost:3000,http://localhost:8000

# =====================================================
# Coach Chat & Evidence Configuration
# =====================================================
# Coach Model for chat conversations (via OpenRouter)
# Default: gpt-4o-mini for cost-effective coaching
COACH_MODEL=openai/gpt-4o-mini

# Maximum user messages per conversation (AD-9)
# After this limit, chat becomes read-only with a redirect message
MAX_CHAT_TURNS=15

# Number of recent messages to include in LLM context (AD-4)
# Token windowing: only last N messages sent to LLM to save tokens
CHAT_HISTORY_WINDOW=6

# Anchor character length for evidence verification (AD-2)
# Used for 5-stage self-healing evidence verification
EVIDENCE_ANCHOR_LEN=25

# Search tolerance window for anchor tail search (AD-2)
# Characters to search for tail anchor after head is found
EVIDENCE_SEARCH_WINDOW=2000

# =====================================================
# Monitoring & Analytics
# =====================================================
# Enable LLM call logging
ENABLE_LLM_LOGGING=true

# Log LLM calls to JSONL file
LLM_LOG_FILE=data/logs/llm_calls.jsonl
