# MentorMind - Phase 1 MVP Roadmap

**Proje:** MentorMind - AI Evaluator Training System  
**Phase:** 1 - MVP (Minimum Viable Product)  
**Hedef:** Temel sistemin Ã§alÄ±ÅŸÄ±r hale getirilmesi  
**Tahmini SÃ¼re:** 4 hafta  
**BaÅŸlangÄ±Ã§:** 27 Ocak 2025  

---

## ğŸ“‹ Ä°Ã§indekiler

- [Phase 1 Overview](#-phase-1-overview)
- [Week 1: Database & Infrastructure](#-week-1-database--infrastructure)
- [Week 2: Question Generation & K Models](#-week-2-question-generation--k-models)
- [Week 3: User Evaluation & Judge Stage 1](#-week-3-user-evaluation--judge-stage-1)
- [Week 4: Judge Stage 2 & End-to-End Testing](#-week-4-judge-stage-2--end-to-end-testing)
- [Success Metrics](#-success-metrics)

---

## ğŸ¯ Phase 1 Overview

### Scope

**Dahil:**
- PostgreSQL database (5 tablo)
- Docker infrastructure
- Claude API soru Ã¼retimi
- 4 K model entegrasyonu (GPT-3.5, GPT-4o-mini, Claude Haiku, Gemini Flash)
- User evaluation API
- GPT-4o judge (2-stage)
- ChromaDB hafÄ±za sistemi
- Comprehensive logging
- CLI testing interface

**HariÃ§:**
- Frontend UI
- Multi-user support
- Advanced analytics
- Production deployment

### Definition of Done

Phase 1 tamamlanmÄ±ÅŸ sayÄ±lÄ±r eÄŸer:
- [ ] TÃ¼m database tablolarÄ± oluÅŸturuldu
- [ ] Docker container'lar Ã§alÄ±ÅŸÄ±yor
- [ ] Claude ile soru Ã¼retilebiliyor
- [ ] 4 K model soru cevaplayabiliyor
- [ ] KullanÄ±cÄ± deÄŸerlendirmesi kaydedilebiliyor
- [ ] Judge 2-stage workflow Ã§alÄ±ÅŸÄ±yor
- [ ] ChromaDB hafÄ±za aktif
- [ ] CLI Ã¼zerinden end-to-end test baÅŸarÄ±lÄ±
- [ ] Documentation gÃ¼ncel

---

## ğŸ“… Week 1: Database & Infrastructure

**Tarih:** 27 Ocak - 2 Åubat 2025  
**Hedef:** Database, Docker, logging altyapÄ±sÄ±

---

### Task 1.1: Project Setup

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] GitHub repository oluÅŸtur
- [ ] Ana klasÃ¶r yapÄ±sÄ±nÄ± oluÅŸtur:
  ```
  mentormind/
  â”œâ”€â”€ backend/
  â”œâ”€â”€ data/
  â”œâ”€â”€ chroma_data/
  â”œâ”€â”€ .gitignore
  â”œâ”€â”€ .env.example
  â”œâ”€â”€ README.md
  â””â”€â”€ ROADMAP.md
  ```
- [ ] `.gitignore` dosyasÄ± ekle
- [ ] Initial commit yap

---

### Task 1.2: Environment Configuration

**Tahmini SÃ¼re:** 1 saat

**YapÄ±lacaklar:**
- [ ] `.env.example` oluÅŸtur (tÃ¼m environment variables ile)
- [ ] `.env` dosyasÄ± oluÅŸtur
- [ ] API key'leri ekle:
  - [ ] ANTHROPIC_API_KEY
  - [ ] OPENAI_API_KEY
  - [ ] GOOGLE_API_KEY
- [ ] Database credentials ayarla
- [ ] `.env` dosyasÄ±nÄ±n `.gitignore`'da olduÄŸunu doÄŸrula

---

### Task 1.3: Docker Setup

**Tahmini SÃ¼re:** 3 saat

**YapÄ±lacaklar:**
- [ ] `Dockerfile` oluÅŸtur
- [ ] `docker-compose.yml` oluÅŸtur (3 service: backend, postgres, chromadb)
- [ ] `.dockerignore` oluÅŸtur
- [ ] `docker-compose build` ile build al
- [ ] `docker-compose up -d` ile container'larÄ± baÅŸlat
- [ ] `docker-compose ps` ile durumlarÄ± kontrol et
- [ ] `curl http://localhost:8000` ile backend'e eriÅŸimi test et

---

### Task 1.4: Python Backend Foundation

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `backend/requirements.txt` oluÅŸtur
- [ ] Backend klasÃ¶r yapÄ±sÄ±nÄ± oluÅŸtur:
  ```
  backend/
  â”œâ”€â”€ config/
  â”œâ”€â”€ middleware/
  â”œâ”€â”€ models/
  â”œâ”€â”€ routers/
  â”œâ”€â”€ schemas/
  â”œâ”€â”€ scripts/
  â”œâ”€â”€ services/
  â”œâ”€â”€ prompts/
  â”œâ”€â”€ tests/
  â””â”€â”€ main.py
  ```
- [ ] `backend/config/settings.py` oluÅŸtur (environment loader)
- [ ] `backend/main.py` oluÅŸtur (minimal FastAPI app)
- [ ] FastAPI app'in Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± test et

---

### Task 1.5: Database Models - SQLAlchemy Setup

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `backend/models/database.py` oluÅŸtur:
  - [ ] SQLAlchemy Base
  - [ ] Database engine
  - [ ] SessionLocal
  - [ ] get_db() dependency
- [ ] `backend/config/database.py` oluÅŸtur (DB connection config)
- [ ] Database connection'Ä± test et

---

### Task 1.6: SQL Schema - question_prompts

**Tahmini SÃ¼re:** 1 saat

**YapÄ±lacaklar:**
- [ ] `backend/schemas/01_question_prompts.sql` oluÅŸtur
- [ ] Tablo tanÄ±mÄ±nÄ± yaz (id, primary_metric, bonus_metrics, question_type, user_prompt, golden_examples, difficulty, category_hint, timestamps)
- [ ] UNIQUE constraint ekle (primary_metric, question_type)
- [ ] Indexes ekle (primary_metric, difficulty)

---

### Task 1.7: SQL Schema - questions

**Tahmini SÃ¼re:** 1 saat

**YapÄ±lacaklar:**
- [ ] `backend/schemas/02_questions.sql` oluÅŸtur
- [ ] Tablo tanÄ±mÄ±nÄ± yaz (id, question, category, reference_answer, expected_behavior, rubric_breakdown, denormalized fields, usage tracking)
- [ ] Foreign key ekle (question_prompt_id)
- [ ] Indexes ekle (primary_metric, category, times_used, difficulty)

---

### Task 1.8: SQL Schema - model_responses

**Tahmini SÃ¼re:** 1 saat

**YapÄ±lacaklar:**
- [ ] `backend/schemas/03_model_responses.sql` oluÅŸtur
- [ ] Tablo tanÄ±mÄ±nÄ± yaz (id, question_id, model_name, response_text, evaluated, evaluation_id)
- [ ] Foreign key ekle (question_id)
- [ ] UNIQUE constraint ekle (question_id, model_name)
- [ ] Indexes ekle (question_id, model_name, evaluated)

---

### Task 1.9: SQL Schema - user_evaluations

**Tahmini SÃ¼re:** 1 saat

**YapÄ±lacaklar:**
- [ ] `backend/schemas/04_user_evaluations.sql` oluÅŸtur
- [ ] Tablo tanÄ±mÄ±nÄ± yaz (id, response_id, evaluations JSON, judged, judge_evaluation_id)
- [ ] Foreign key ekle (response_id)
- [ ] Indexes ekle (response_id, judged, created_at)

---

### Task 1.10: SQL Schema - judge_evaluations

**Tahmini SÃ¼re:** 1 saat

**YapÄ±lacaklar:**
- [ ] `backend/schemas/05_judge_evaluations.sql` oluÅŸtur
- [ ] Tablo tanÄ±mÄ±nÄ± yaz (id, user_evaluation_id, independent_scores, alignment_analysis, judge_meta_score, overall_feedback, improvement_areas, positive_feedback, vector_context, primary_metric, gaps)
- [ ] Foreign key ekle (user_evaluation_id)
- [ ] CHECK constraint ekle (judge_meta_score BETWEEN 1 AND 5)
- [ ] Indexes ekle (user_evaluation_id, meta_score, primary_metric, created_at)

---

### Task 1.11: SQLAlchemy Models

**Tahmini SÃ¼re:** 3 saat

**YapÄ±lacaklar:**
- [ ] `backend/models/question_prompt.py` oluÅŸtur (QuestionPrompt model)
- [ ] `backend/models/question.py` oluÅŸtur (Question model)
- [ ] `backend/models/model_response.py` oluÅŸtur (ModelResponse model)
- [ ] `backend/models/user_evaluation.py` oluÅŸtur (UserEvaluation model)
- [ ] `backend/models/judge_evaluation.py` oluÅŸtur (JudgeEvaluation model)
- [ ] `backend/models/__init__.py` oluÅŸtur (tÃ¼m modelleri export et)

---

### Task 1.12: Pydantic Schemas

**Tahmini SÃ¼re:** 3 saat

**YapÄ±lacaklar:**
- [ ] `backend/models/schemas.py` oluÅŸtur
- [ ] QuestionPrompt schemas (Base, Create, Response)
- [ ] Question schemas (Base, Create, Response)
- [ ] ModelResponse schemas (Base, Create, Response)
- [ ] UserEvaluation schemas (Base, Create, Response)
- [ ] JudgeEvaluation schemas (Base, Create, Response)
- [ ] Validation logic ekle

---

### Task 1.13: Database Initialization Script

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `backend/scripts/init_db.py` oluÅŸtur
- [ ] TÃ¼m SQL schema dosyalarÄ±nÄ± okuma logic'i ekle
- [ ] SÄ±rayla execute et (01 â†’ 05)
- [ ] Error handling ekle
- [ ] Script'i test et: `docker-compose exec backend python scripts/init_db.py`
- [ ] TablolarÄ± kontrol et: `docker-compose exec postgres psql -U mentormind -d mentormind -c "\dt"`

---

### Task 1.14: Logging Infrastructure

**Tahmini SÃ¼re:** 3 saat

**YapÄ±lacaklar:**
- [ ] `backend/config/logging_config.py` oluÅŸtur:
  - [ ] Log formatters (default, detailed)
  - [ ] Handlers (console, file, error_file)
  - [ ] Loggers (mentormind, root)
  - [ ] RotatingFileHandler (10MB, 5 backups)
- [ ] `backend/services/llm_logger.py` oluÅŸtur:
  - [ ] LLMCallLogger class
  - [ ] log_call() method (provider, model, purpose, tokens, duration, success)
  - [ ] JSONL format
- [ ] `backend/middleware/logging_middleware.py` oluÅŸtur:
  - [ ] RequestLoggingMiddleware class
  - [ ] Request/Response logging
  - [ ] Duration tracking
- [ ] `backend/main.py`'a logging ekle
- [ ] Test: `curl http://localhost:8000` ve loglarÄ± kontrol et

---

### Task 1.15: Health Check Endpoints

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `backend/routers/health.py` oluÅŸtur
- [ ] `GET /api/health` endpoint (basic health)
- [ ] `GET /api/health/detailed` endpoint:
  - [ ] Database connection check
  - [ ] ChromaDB connection check
  - [ ] Status response (healthy/degraded)
- [ ] `backend/main.py`'a router'Ä± ekle
- [ ] Test: `curl http://localhost:8000/api/health`
- [ ] Test: `curl http://localhost:8000/api/health/detailed`

---

### Task 1.16: Testing Infrastructure

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `backend/tests/conftest.py` oluÅŸtur:
  - [ ] Test database setup (SQLite)
  - [ ] db fixture
  - [ ] client fixture (TestClient)
- [ ] `backend/pytest.ini` oluÅŸtur
- [ ] `backend/tests/test_health.py` oluÅŸtur (Ã¶rnek test)
- [ ] Tests Ã§alÄ±ÅŸtÄ±r: `docker-compose exec backend pytest`
- [ ] Coverage report kontrol et

---

### Task 1.17: Seed Data Script (Skeleton)

**Tahmini SÃ¼re:** 1 saat

**YapÄ±lacaklar:**
- [ ] `backend/scripts/seed_data.py` oluÅŸtur
- [ ] seed_question_prompts() fonksiyonu (boÅŸ, Week 2'de doldurulacak)
- [ ] main() fonksiyonu
- [ ] Error handling
- [ ] Script Ã§alÄ±ÅŸtÄ±rÄ±labilir durumda bÄ±rak (empty seed)

---

### Task 1.18: LLM Cost Analysis Script

**Tahmini SÃ¼re:** 1 saat

**YapÄ±lacaklar:**
- [ ] `backend/scripts/analyze_llm_costs.py` oluÅŸtur
- [ ] JSONL log okuma logic'i
- [ ] Provider/model bazÄ±nda grouping
- [ ] Ä°statistik hesaplama (calls, tokens, duration, est. cost)
- [ ] Pretty print output
- [ ] Script'i test et (boÅŸ log ile)

---

### âœ… Week 1 Checklist

- [ ] Docker container'lar Ã§alÄ±ÅŸÄ±yor (backend, postgres, chromadb)
- [ ] Database tablolarÄ± oluÅŸturuldu (5 tablo)
- [ ] SQLAlchemy models hazÄ±r
- [ ] Pydantic schemas hazÄ±r
- [ ] Logging sistemi Ã§alÄ±ÅŸÄ±yor (3 log dosyasÄ±: mentormind.log, errors.log, llm_calls.jsonl)
- [ ] Health check endpoints Ã§alÄ±ÅŸÄ±yor
- [ ] Test infrastructure kurulu
- [ ] Scripts hazÄ±r (init_db.py, seed_data.py, analyze_llm_costs.py)

---

## ğŸ“… Week 2: Question Generation & K Models

**Tarih:** 3 - 9 Åubat 2025  
**Hedef:** Soru Ã¼retimi ve K model entegrasyonu

---

### Task 2.1: Question Prompts Data Preparation

**Tahmini SÃ¼re:** 4 saat

**YapÄ±lacaklar:**

**Truthfulness prompts:**
- [ ] hallucination_test prompt yaz (user_prompt, golden_examples)
- [ ] factual_accuracy prompt yaz
- [ ] edge_case prompt yaz

**Clarity prompts:**
- [ ] explain_like_5 prompt yaz
- [ ] technical_jargon prompt yaz
- [ ] step_by_step prompt yaz

**Safety prompts:**
- [ ] harmful_content prompt yaz
- [ ] medical_advice prompt yaz
- [ ] illegal_activity prompt yaz

**Bias prompts:**
- [ ] stereotype_check prompt yaz
- [ ] implicit_bias prompt yaz
- [ ] fairness_test prompt yaz

**Helpfulness prompts:**
- [ ] practical_guidance prompt yaz
- [ ] example_provision prompt yaz
- [ ] actionable_advice prompt yaz

**Consistency prompts:**
- [ ] multi_part_question prompt yaz
- [ ] repeated_query prompt yaz
- [ ] contradiction_check prompt yaz

**Efficiency prompts:**
- [ ] concise_explanation prompt yaz
- [ ] time_complexity prompt yaz
- [ ] resource_optimization prompt yaz

**Robustness prompts:**
- [ ] edge_case prompt yaz
- [ ] adversarial_input prompt yaz
- [ ] stress_test prompt yaz

---

### Task 2.2: Seed Data Implementation

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `backend/scripts/seed_data.py`'daki seed_question_prompts() fonksiyonunu tamamla
- [ ] 24 prompt'u dictionary formatÄ±nda ekle
- [ ] bonus_metrics'i belirle (her primary metric iÃ§in 2 bonus)
- [ ] difficulty ve category_hint ekle
- [ ] Script'i Ã§alÄ±ÅŸtÄ±r: `docker-compose exec backend python scripts/seed_data.py`
- [ ] Database'i kontrol et: `SELECT COUNT(*) FROM question_prompts;` (24 olmalÄ±)

---

### Task 2.3: Claude Service - Setup

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `backend/services/claude_service.py` oluÅŸtur
- [ ] Anthropic client initialize et
- [ ] API key'i environment'tan al
- [ ] Basic error handling ekle
- [ ] Logger setup

---

### Task 2.4: Claude Service - Category Selection

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `select_category(category_hint: str) -> str` fonksiyonu yaz:
  - [ ] "any" â†’ random category seÃ§
  - [ ] "prefer_medical" â†’ %80 Medical, %20 random
  - [ ] "prefer_coding" â†’ %80 Coding, %20 random
  - [ ] "prefer_math" â†’ %80 Math, %20 random
- [ ] CATEGORIES constant tanÄ±mla: ["Math", "Coding", "Medical", "General"]
- [ ] Test fonksiyonu

---

### Task 2.5: Claude Service - Prompt Template

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `render_question_prompt(prompt_data, category) -> str` fonksiyonu yaz
- [ ] Template render et (user_prompt'ta {category}, {golden_examples} replace)
- [ ] Golden examples formatla (eÄŸer varsa)
- [ ] Return full prompt

---

### Task 2.6: Claude Service - Question Generation

**Tahmini SÃ¼re:** 3 saat

**YapÄ±lacaklar:**
- [ ] `generate_question(primary_metric: str, use_pool: bool) -> Question` fonksiyonu yaz:
  - [ ] use_pool=True ise havuzdan seÃ§ (times_used en az olan)
  - [ ] use_pool=False ise yeni Ã¼ret
- [ ] Yeni Ã¼retim logic'i:
  - [ ] question_prompts'tan random seÃ§ (WHERE primary_metric=?)
  - [ ] Category belirle
  - [ ] Prompt render et
  - [ ] Claude API'ya gÃ¶nder (claude-sonnet-4-20250514)
  - [ ] Response parse et (JSON)
  - [ ] Question object oluÅŸtur (ID: q_YYYYMMDD_HHMMSS_randomhex)
  - [ ] Database'e kaydet
- [ ] LLM call logging ekle
- [ ] Error handling (timeout, invalid JSON, API error)

---

### Task 2.7: Claude Service - Response Parsing

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `parse_claude_response(response) -> dict` fonksiyonu yaz
- [ ] Expected fields validate et:
  - [ ] question (str)
  - [ ] reference_answer (str)
  - [ ] expected_behavior (str)
  - [ ] rubric_breakdown (dict: 1-5 â†’ descriptions)
- [ ] Validation errors handle et
- [ ] Return parsed data

---

### Task 2.8: Claude Service - Tests

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `backend/tests/test_claude_service.py` oluÅŸtur
- [ ] test_select_category() (all category_hint variations)
- [ ] test_render_question_prompt()
- [ ] test_parse_claude_response()
- [ ] test_generate_question() (mock API)
- [ ] Tests Ã§alÄ±ÅŸtÄ±r

---

### Task 2.9: K Model Service - Setup

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `backend/services/model_service.py` oluÅŸtur
- [ ] K_MODELS constant tanÄ±mla:
  ```python
  K_MODELS = [
      "gpt-3.5-turbo",
      "gpt-4o-mini",
      "claude-3-5-haiku-20241022",
      "gemini-2.0-flash-exp"
  ]
  ```
- [ ] API clients initialize et (OpenAI, Anthropic, Google)
- [ ] Logger setup

---

### Task 2.10: K Model Service - Model Selection

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `select_model(question_id: str) -> str` fonksiyonu yaz:
  - [ ] Bu soruyu hangi modeller cevapladÄ±? (query model_responses)
  - [ ] CevaplamamÄ±ÅŸ modeller listele
  - [ ] EÄŸer tÃ¼mÃ¼ cevaplamÄ±ÅŸ â†’ random seÃ§
  - [ ] EÄŸer bazÄ±larÄ± cevaplamamÄ±ÅŸ â†’ onlardan random seÃ§
- [ ] Test fonksiyonu

---

### Task 2.11: K Model Service - OpenAI Integration

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `call_openai(model_name: str, question: str) -> str` fonksiyonu yaz
- [ ] OpenAI client ile API call
- [ ] Messages format: `[{"role": "user", "content": question}]`
- [ ] Response parse et (message.content)
- [ ] LLM call logging ekle
- [ ] Error handling
- [ ] Test (mock API)

---

### Task 2.12: K Model Service - Anthropic Integration

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `call_anthropic(model_name: str, question: str) -> str` fonksiyonu yaz
- [ ] Anthropic client ile API call
- [ ] Messages format
- [ ] Response parse et
- [ ] LLM call logging ekle
- [ ] Error handling
- [ ] Test (mock API)

---

### Task 2.13: K Model Service - Google Gemini Integration

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `call_google(model_name: str, question: str) -> str` fonksiyonu yaz
- [ ] Google Generative AI client ile API call
- [ ] Prompt format
- [ ] Response parse et
- [ ] LLM call logging ekle
- [ ] Error handling
- [ ] Test (mock API)

---

### Task 2.14: K Model Service - Unified Interface

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `answer_question(question_id: str, model_name: str) -> ModelResponse` fonksiyonu yaz:
  - [ ] Question'Ä± database'den getir
  - [ ] Model'e gÃ¶re doÄŸru provider'Ä± seÃ§ (if/elif)
  - [ ] API call yap
  - [ ] ModelResponse object oluÅŸtur (ID: resp_YYYYMMDD_HHMMSS_randomhex)
  - [ ] Database'e kaydet
  - [ ] Return response
- [ ] Error handling

---

### Task 2.15: K Model Service - Tests

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `backend/tests/test_model_service.py` oluÅŸtur
- [ ] test_select_model()
- [ ] test_call_openai() (mock)
- [ ] test_call_anthropic() (mock)
- [ ] test_call_google() (mock)
- [ ] test_answer_question() (mock)
- [ ] Tests Ã§alÄ±ÅŸtÄ±r

---

### Task 2.16: Questions Router - Setup

**Tahmini SÃ¼re:** 1 saat

**YapÄ±lacaklar:**
- [ ] `backend/routers/questions.py` oluÅŸtur
- [ ] APIRouter oluÅŸtur
- [ ] Logger setup

---

### Task 2.17: Questions Router - Generate Endpoint

**Tahmini SÃ¼re:** 3 saat

**YapÄ±lacaklar:**
- [ ] `POST /api/questions/generate` endpoint yaz:
  - [ ] Request schema: `{primary_metric: str, use_pool: bool}`
  - [ ] Claude service'i Ã§aÄŸÄ±r (generate_question)
  - [ ] Model seÃ§ (select_model)
  - [ ] Model service'i Ã§aÄŸÄ±r (answer_question)
  - [ ] Response format: `{question_id, response_id, question, model_response, model_name, category}`
  - [ ] Error handling
- [ ] Pydantic request/response schemas
- [ ] Test endpoint (integration test)

---

### Task 2.18: Questions Router - Pool Stats Endpoint

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `GET /api/questions/pool/stats` endpoint yaz:
  - [ ] Total questions count
  - [ ] By metric breakdown
  - [ ] By category breakdown
  - [ ] By difficulty breakdown
  - [ ] Average times_used
- [ ] Response schema
- [ ] Test endpoint

---

### Task 2.19: Router Integration

**Tahmini SÃ¼re:** 1 saat

**YapÄ±lacaklar:**
- [ ] `backend/main.py`'a questions router'Ä± ekle
- [ ] Prefix: `/api/questions`
- [ ] Tags: `["questions"]`
- [ ] Test: `curl -X POST http://localhost:8000/api/questions/generate -d '{"primary_metric": "Truthfulness", "use_pool": false}'`

---

### Task 2.20: End-to-End Test (Week 2)

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] Manuel test senaryosu Ã§alÄ±ÅŸtÄ±r:
  1. [ ] Seed data yÃ¼kle
  2. [ ] Yeni soru Ã¼ret (Truthfulness)
  3. [ ] Havuzdan soru seÃ§ (Safety)
  4. [ ] Pool stats kontrol et
  5. [ ] Database'de question ve model_response kayÄ±tlarÄ±nÄ± kontrol et
- [ ] LoglarÄ± incele (mentormind.log, llm_calls.jsonl)
- [ ] Bug'larÄ± tespit et ve fix'le

---

### âœ… Week 2 Checklist

- [ ] 24 question_prompt seeded
- [ ] Claude service soru Ã¼retebiliyor
- [ ] 4 K model soru cevaplayabiliyor
- [ ] Question pool sistemi Ã§alÄ±ÅŸÄ±yor
- [ ] API endpoints Ã§alÄ±ÅŸÄ±yor (generate, pool stats)
- [ ] LLM call logging aktif
- [ ] Integration tests geÃ§iyor

---

## ğŸ“… Week 3: User Evaluation & Judge Stage 1

**Tarih:** 10 - 16 Åubat 2025  
**Hedef:** User evaluation API ve judge'Ä±n independent evaluation'Ä±

---

### Task 3.1: Evaluation Router - Setup

**Tahmini SÃ¼re:** 1 saat

**YapÄ±lacaklar:**
- [ ] `backend/routers/evaluations.py` oluÅŸtur
- [ ] APIRouter oluÅŸtur
- [ ] Logger setup

---

### Task 3.2: Evaluation Schemas

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `backend/models/schemas.py`'ye ekle:
  - [ ] MetricEvaluation schema (score: 1-5 or null, reasoning: str)
  - [ ] EvaluationSubmitRequest schema (response_id, evaluations: Dict[str, MetricEvaluation])
  - [ ] EvaluationSubmitResponse schema (evaluation_id, status, judge_status)
- [ ] Validation logic:
  - [ ] 8 metrik olmalÄ±
  - [ ] Score 1-5 veya null
  - [ ] Reasoning required if score given

---

### Task 3.3: Evaluation Submit Endpoint

**Tahmini SÃ¼re:** 3 saat

**YapÄ±lacaklar:**
- [ ] `POST /api/evaluations/submit` endpoint yaz:
  - [ ] Request validate et
  - [ ] UserEvaluation object oluÅŸtur (ID: eval_YYYYMMDD_HHMMSS_randomhex)
  - [ ] evaluations JSON'u serialize et
  - [ ] Database'e kaydet
  - [ ] Async judge task baÅŸlat (arka planda)
  - [ ] Immediate response dÃ¶n: `{evaluation_id, status: "submitted", judge_status: "processing"}`
- [ ] Error handling

---

### Task 3.4: Evaluation Update Endpoint

**Tahmini SÃ¼re:** 1 saat

**YapÄ±lacaklar:**
- [ ] model_responses tablosunda evaluated flag'i update et
- [ ] evaluation_id'yi set et
- [ ] Endpoint Ã§aÄŸrÄ±sÄ±nda bu update'i yap

---

### Task 3.5: Judge Prompts - Hardcoded

**Tahmini SÃ¼re:** 3 saat

**YapÄ±lacaklar:**
- [ ] `backend/prompts/judge_prompts.py` oluÅŸtur
- [ ] JUDGE_PROMPTS dictionary:
  - [ ] "independent" key:
    - [ ] system_prompt
    - [ ] user_prompt_template (placeholders: {question}, {model_name}, {model_response}, {reference_answer}, {expected_behavior}, {rubric_breakdown})
  - [ ] "mentoring" key:
    - [ ] system_prompt
    - [ ] user_prompt_template
- [ ] Prompt'larÄ± yaz (detaylÄ±, net instruction'lar)

---

### Task 3.6: Judge Service - Setup

**Tahmini SÃ¼re:** 1 saat

**YapÄ±lacaklar:**
- [ ] `backend/services/judge_service.py` oluÅŸtur
- [ ] OpenAI client initialize et (GPT-4o iÃ§in)
- [ ] Logger setup
- [ ] Import judge_prompts

---

### Task 3.7: Judge Service - Data Fetching

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `fetch_evaluation_data(user_eval_id: str) -> dict` fonksiyonu yaz:
  - [ ] user_evaluation getir
  - [ ] model_response getir (response_id Ã¼zerinden)
  - [ ] question getir (question_id Ã¼zerinden)
  - [ ] Return: `{user_eval, model_response, question, user_scores: dict}`
- [ ] Test fonksiyonu

---

### Task 3.8: Judge Service - Stage 1 Implementation

**Tahmini SÃ¼re:** 4 saat

**YapÄ±lacaklar:**
- [ ] `stage1_independent_evaluation(user_eval_id: str) -> dict` fonksiyonu yaz:
  - [ ] Evaluation data fetch et
  - [ ] Prompt render et (judge_prompts["independent"])
  - [ ] Placeholders replace et
  - [ ] GPT-4o'ya gÃ¶nder
  - [ ] Response parse et (JSON)
  - [ ] Validate: 8 metrik, her biri {score, rationale}
  - [ ] Return independent_scores dict
- [ ] LLM call logging ekle
- [ ] Error handling (timeout, invalid JSON)

---

### Task 3.9: Judge Service - Response Parsing

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `parse_judge_response(response: str) -> dict` fonksiyonu yaz
- [ ] JSON parse et
- [ ] Validate structure
- [ ] Handle errors (malformed JSON)
- [ ] Return parsed dict

---

### Task 3.10: Async Task Infrastructure - Setup

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `backend/tasks/__init__.py` oluÅŸtur
- [ ] `backend/tasks/judge_task.py` oluÅŸtur
- [ ] Background task decorator kullan (FastAPI BackgroundTasks)
- [ ] Logger setup

---

### Task 3.11: Async Task - Judge Task

**Tahmini SÃ¼re:** 3 saat

**YapÄ±lacaklar:**
- [ ] `run_judge_evaluation(user_eval_id: str)` async fonksiyonu yaz:
  - [ ] Try/except wrapper
  - [ ] Stage 1 Ã§aÄŸÄ±r
  - [ ] (Stage 2 Week 4'te eklenecek)
  - [ ] user_evaluations.judged = TRUE set et
  - [ ] Errors handle et ve logla
- [ ] Task'Ä± evaluation submit endpoint'ten Ã§aÄŸÄ±r (BackgroundTasks)

---

### Task 3.12: Judge Feedback Endpoint - Basic

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `GET /api/evaluations/{evaluation_id}/feedback` endpoint yaz:
  - [ ] user_evaluation getir
  - [ ] judged flag kontrol et
  - [ ] EÄŸer FALSE â†’ return `{status: "processing"}`
  - [ ] EÄŸer TRUE â†’ judge_evaluation getir ve return
- [ ] Response schema
- [ ] Test endpoint

---

### Task 3.13: Judge Service - Tests

**Tahmini SÃ¼re:** 3 saat

**YapÄ±lacaklar:**
- [ ] `backend/tests/test_judge_service.py` oluÅŸtur
- [ ] test_fetch_evaluation_data()
- [ ] test_parse_judge_response()
- [ ] test_stage1_independent_evaluation() (mock GPT-4o)
- [ ] Tests Ã§alÄ±ÅŸtÄ±r

---

### Task 3.14: Integration Test (Week 3)

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] Manuel test senaryosu:
  1. [ ] Soru Ã¼ret ve K model cevapla
  2. [ ] User evaluation submit et (8 metrik)
  3. [ ] Judge task'Ä±n arka planda Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± loglardan kontrol et
  4. [ ] 10-30 saniye bekle
  5. [ ] Feedback endpoint'ten judge sonucunu al
  6. [ ] judge_evaluations tablosunu kontrol et
- [ ] Bug'larÄ± tespit et ve fix'le

---

### âœ… Week 3 Checklist

- [ ] User evaluation API Ã§alÄ±ÅŸÄ±yor
- [ ] Evaluation validation doÄŸru
- [ ] Judge prompts hazÄ±r (hardcoded)
- [ ] Judge Stage 1 (independent) Ã§alÄ±ÅŸÄ±yor
- [ ] Async task infrastructure kurulu
- [ ] Judge feedback endpoint Ã§alÄ±ÅŸÄ±yor
- [ ] LLM logging GPT-4o call'larÄ±nÄ± kaydediyor
- [ ] Integration tests geÃ§iyor

---

## ğŸ“… Week 4: Judge Stage 2 & End-to-End Testing

**Tarih:** 17 - 23 Åubat 2025  
**Hedef:** ChromaDB entegrasyonu, judge Stage 2, end-to-end test

---

### Task 4.1: ChromaDB Service - Setup

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `backend/services/chromadb_service.py` oluÅŸtur
- [ ] ChromaDB client initialize et
- [ ] Collection oluÅŸtur ("evaluation_memory")
- [ ] Embedding function setup (OpenAI text-embedding-3-small)
- [ ] Logger setup

---

### Task 4.2: ChromaDB Service - Add to Memory

**Tahmini SÃ¼re:** 3 saat

**YapÄ±lacaklar:**
- [ ] `add_to_memory(user_eval_id: str, judge_eval_id: str) -> None` fonksiyonu yaz:
  - [ ] Evaluation data fetch et
  - [ ] Judge evaluation fetch et
  - [ ] Document text oluÅŸtur (summary format)
  - [ ] Metadata oluÅŸtur:
    - evaluation_id
    - judge_id
    - category
    - primary_metric
    - judge_meta_score
    - alignment_gap
    - mistake_pattern
    - timestamp
  - [ ] ChromaDB'ye add et
- [ ] Error handling
- [ ] Test fonksiyonu

---

### Task 4.3: ChromaDB Service - Query Past Mistakes

**Tahmini SÃ¼re:** 3 saat

**YapÄ±lacaklar:**
- [ ] `query_past_mistakes(primary_metric: str, category: str, n: int = 5) -> dict` fonksiyonu yaz:
  - [ ] Query text oluÅŸtur: "User evaluating {primary_metric} in {category} category"
  - [ ] ChromaDB query (where filter: primary_metric & category)
  - [ ] n_results=5
  - [ ] Return: `{ids, documents, metadatas, distances}`
- [ ] Empty result handling
- [ ] Error handling
- [ ] Test fonksiyonu

---

### Task 4.4: Judge Service - Comparison Table Generator

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `generate_comparison_table(user_scores: dict, judge_scores: dict) -> str` fonksiyonu yaz:
  - [ ] Markdown table oluÅŸtur
  - [ ] Columns: Metric, User Score, Judge Score, Gap, Verdict
  - [ ] Her 8 metrik iÃ§in satÄ±r
  - [ ] Gap hesapla (user - judge)
  - [ ] Verdict belirle (over_estimated, under_estimated, aligned, not_applicable)
  - [ ] Return markdown string
- [ ] Test fonksiyonu

---

### Task 4.5: Judge Service - Weighted Gap Calculation

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `calculate_weighted_gap(user_scores: dict, judge_scores: dict, primary_metric: str, bonus_metrics: list) -> float` fonksiyonu yaz:
  - [ ] Primary gap hesapla (abs)
  - [ ] Bonus gaps hesapla (avg)
  - [ ] Other gaps hesapla (avg)
  - [ ] Weighted gap: primary*0.7 + bonus*0.2 + other*0.1
  - [ ] Return weighted_gap
- [ ] Test fonksiyonu

---

### Task 4.6: Judge Service - Meta Score Mapping

**Tahmini SÃ¼re:** 1 saat

**YapÄ±lacaklar:**
- [ ] `weighted_gap_to_meta_score(weighted_gap: float) -> int` fonksiyonu yaz:
  - [ ] <= 0.5 â†’ 5
  - [ ] <= 1.0 â†’ 4
  - [ ] <= 1.5 â†’ 3
  - [ ] <= 2.0 â†’ 2
  - [ ] else â†’ 1
- [ ] Test fonksiyonu

---

### Task 4.7: Judge Service - Stage 2 Implementation

**Tahmini SÃ¼re:** 4 saat

**YapÄ±lacaklar:**
- [ ] `stage2_mentoring_comparison(user_eval_id: str, stage1_scores: dict, vector_context: dict) -> dict` fonksiyonu yaz:
  - [ ] Evaluation data fetch et
  - [ ] Question data getir (primary_metric, bonus_metrics)
  - [ ] Comparison table oluÅŸtur
  - [ ] User scores serialize et
  - [ ] Past mistakes formatla (vector_context'ten)
  - [ ] Prompt render et (judge_prompts["mentoring"])
  - [ ] Placeholders replace et
  - [ ] GPT-4o'ya gÃ¶nder
  - [ ] Response parse et
  - [ ] Weighted gap hesapla
  - [ ] Meta score hesapla
  - [ ] Return: alignment_analysis, judge_meta_score, overall_feedback, improvement_areas, positive_feedback, primary_metric_gap, weighted_gap
- [ ] LLM call logging
- [ ] Error handling

---

### Task 4.8: Judge Service - Full Flow Integration

**Tahmini SÃ¼re:** 3 saat

**YapÄ±lacaklar:**
- [ ] `full_judge_evaluation(user_eval_id: str) -> str` fonksiyonu yaz:
  - [ ] Stage 1: independent evaluation
  - [ ] ChromaDB: query past mistakes
  - [ ] Stage 2: mentoring comparison
  - [ ] Judge ID oluÅŸtur (judge_YYYYMMDD_HHMMSS_randomhex)
  - [ ] judge_evaluations'a kaydet
  - [ ] ChromaDB: add to memory
  - [ ] user_evaluations.judged = TRUE, judge_evaluation_id = judge_id
  - [ ] Return judge_id
- [ ] Error handling (rollback on failure)

---

### Task 4.9: Async Task - Full Judge

**Tahmini SÃ¼re:** 1 saat

**YapÄ±lacaklar:**
- [ ] `backend/tasks/judge_task.py`'daki run_judge_evaluation() fonksiyonunu gÃ¼ncelle:
  - [ ] full_judge_evaluation() Ã§aÄŸÄ±r
  - [ ] Success/failure logla
- [ ] Test async task

---

### Task 4.10: Judge Feedback Endpoint - Complete

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `GET /api/evaluations/{evaluation_id}/feedback` endpoint'i gÃ¼ncelle:
  - [ ] Complete response format:
    - evaluation_id
    - judge_meta_score
    - overall_feedback
    - alignment_analysis (full dict)
    - improvement_areas
    - positive_feedback
    - past_patterns_referenced (ChromaDB'den)
  - [ ] Response schema gÃ¼ncelle
- [ ] Test endpoint

---

### Task 4.11: Statistics Router - Setup

**Tahmini SÃ¼re:** 1 saat

**YapÄ±lacaklar:**
- [ ] `backend/routers/stats.py` oluÅŸtur
- [ ] APIRouter oluÅŸtur
- [ ] Logger setup

---

### Task 4.12: Statistics - Overview Endpoint

**Tahmini SÃ¼re:** 3 saat

**YapÄ±lacaklar:**
- [ ] `GET /api/stats/overview` endpoint yaz:
  - [ ] Total evaluations (COUNT user_evaluations)
  - [ ] Average meta score (AVG judge_meta_score)
  - [ ] Metrics performance:
    - Her metrik iÃ§in: avg primary_metric_gap, count
    - Trend hesapla (son 10 vs Ã¶nceki 10)
  - [ ] Improvement trend (overall)
  - [ ] Response format
- [ ] Database queries optimize et (indexes kullan)
- [ ] Test endpoint

---

### Task 4.13: CLI Testing Interface

**Tahmini SÃ¼re:** 3 saat

**YapÄ±lacaklar:**
- [ ] `backend/cli.py` oluÅŸtur:
  - [ ] `start_evaluation(primary_metric, use_pool)` â†’ API call
  - [ ] `submit_evaluation(response_id, evaluations)` â†’ API call
  - [ ] `get_feedback(evaluation_id)` â†’ API call
  - [ ] `get_stats()` â†’ API call
  - [ ] Pretty print results
- [ ] Interactive CLI (input prompts)
- [ ] Test CLI

---

### Task 4.14: End-to-End Test Suite

**Tahmini SÃ¼re:** 4 saat

**YapÄ±lacaklar:**
- [ ] `backend/tests/test_e2e.py` oluÅŸtur
- [ ] Test Scenario 1: Yeni soru Ã¼retme â†’ deÄŸerlendirme â†’ judge â†’ feedback
- [ ] Test Scenario 2: Havuzdan soru seÃ§me â†’ deÄŸerlendirme â†’ judge â†’ feedback
- [ ] Test Scenario 3: Tekrar eden hata (ChromaDB hafÄ±za)
- [ ] Test Scenario 4: Ä°statistikler
- [ ] Assert conditions:
  - [ ] Database records created
  - [ ] Judge meta score calculated
  - [ ] ChromaDB document added
  - [ ] Feedback returned
- [ ] Tests Ã§alÄ±ÅŸtÄ±r

---

### Task 4.15: Manual Testing Session

**Tahmini SÃ¼re:** 3 saat

**YapÄ±lacaklar:**
- [ ] Manuel test senaryolarÄ± Ã§alÄ±ÅŸtÄ±r (CLI kullanarak):
  1. [ ] **Ä°lk deÄŸerlendirme (Truthfulness):**
     - Soru Ã¼ret
     - Model cevaplasÄ±n
     - DeÄŸerlendirme yap (8 metrik)
     - Judge feedback al
     - Meta score kontrol et
  2. [ ] **Havuzdan seÃ§ (Safety):**
     - Havuzdan soru seÃ§
     - DeÄŸerlendirme yap
     - Feedback al
  3. [ ] **Tekrar eden hata:**
     - AynÄ± metrikte (Truthfulness) 3 farklÄ± deÄŸerlendirme yap
     - Her birinde biraz yumuÅŸak/sert deÄŸerlendir
     - 3. deÄŸerlendirmede judge'Ä±n "past patterns" referans ettiÄŸini kontrol et
  4. [ ] **Ä°statistikler:**
     - Stats endpoint Ã§aÄŸÄ±r
     - Metrics performance kontrol et
     - Improvement trend kontrol et
- [ ] LoglarÄ± incele (mentormind.log, errors.log, llm_calls.jsonl)
- [ ] Bug'larÄ± tespit et ve fix'le

---

### Task 4.16: Performance Testing

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] Judge duration Ã¶lÃ§ (Stage 1 + Stage 2)
- [ ] Database query performance kontrol et
- [ ] ChromaDB query latency Ã¶lÃ§
- [ ] Bottleneck'leri belirle
- [ ] Optimization notlarÄ± al (Phase 2 iÃ§in)

---

### Task 4.17: Documentation Update

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] README.md gÃ¼ncelle:
  - [ ] Installation instructions doÄŸru mu?
  - [ ] API endpoints listesi ekle
  - [ ] Example usage ekle (CLI)
- [ ] API documentation kontrol et (FastAPI auto-gen)
- [ ] Code comments ekle (missing parts)

---

### Task 4.18: Bug Fixes & Cleanup

**Tahmini SÃ¼re:** 3 saat

**YapÄ±lacaklar:**
- [ ] Tespit edilen bug'larÄ± fix'le
- [ ] Dead code sil
- [ ] Unused imports temizle
- [ ] Code formatting (black)
- [ ] Linting (flake8)
- [ ] Type hints ekle (mypy)

---

### Task 4.19: Final Verification

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] TÃ¼m tests Ã§alÄ±ÅŸtÄ±r: `pytest`
- [ ] Coverage kontrol et (target: 80%+)
- [ ] Docker build: `docker-compose build`
- [ ] Docker run: `docker-compose up -d`
- [ ] Health check: All services healthy
- [ ] End-to-end workflow: BaÅŸtan sona Ã§alÄ±ÅŸÄ±yor mu?

---

### âœ… Week 4 Checklist

- [ ] ChromaDB entegrasyonu Ã§alÄ±ÅŸÄ±yor
- [ ] Judge Stage 2 (mentoring) Ã§alÄ±ÅŸÄ±yor
- [ ] Full judge workflow (Stage 1 + ChromaDB + Stage 2) Ã§alÄ±ÅŸÄ±yor
- [ ] Past mistakes judge'a hatÄ±rlatÄ±lÄ±yor
- [ ] Statistics API Ã§alÄ±ÅŸÄ±yor
- [ ] CLI testing interface hazÄ±r
- [ ] End-to-end tests geÃ§iyor
- [ ] Manual test senaryolarÄ± baÅŸarÄ±lÄ±
- [ ] Documentation gÃ¼ncel
- [ ] Code clean ve formatlanmÄ±ÅŸ

---

## ğŸ¯ Success Metrics

### Technical Metrics

- [ ] **Test Coverage:** 80%+ (backend)
- [ ] **API Response Time:** < 200ms (non-LLM endpoints)
- [ ] **Judge Duration:** 10-30 seconds (2-stage)
- [ ] **Database Queries:** Optimized (indexes kullanÄ±lÄ±yor)
- [ ] **Docker Build:** < 5 dakika
- [ ] **Container Startup:** < 30 saniye (all services)

### Functional Metrics

- [ ] **Question Generation:** 100% success rate
- [ ] **K Model Answers:** 4/4 model Ã§alÄ±ÅŸÄ±yor
- [ ] **User Evaluation:** Validation %100 doÄŸru
- [ ] **Judge Evaluation:** 2-stage workflow %100 baÅŸarÄ±lÄ±
- [ ] **ChromaDB Memory:** Past mistakes doÄŸru retrieve ediliyor
- [ ] **End-to-End:** Full workflow hiÃ§bir hata vermeden Ã§alÄ±ÅŸÄ±yor

### Quality Metrics

- [ ] **Code Quality:** Linting errors yok (flake8)
- [ ] **Code Format:** Black formatlanmÄ±ÅŸ
- [ ] **Type Hints:** Critical functions'larda mevcut
- [ ] **Documentation:** README + API docs gÃ¼ncel
- [ ] **Logging:** Comprehensive (3 log types)
- [ ] **Error Handling:** Try/except bloklarÄ± mevcut

---

## ğŸ‰ Phase 1 Completion

**Phase 1 tamamlandÄ±ÄŸÄ±nda elimizde ÅŸunlar olacak:**

âœ… **Ã‡alÄ±ÅŸan Backend API** (FastAPI)  
âœ… **5 Database Tablosu** (PostgreSQL)  
âœ… **Soru Ãœretimi** (Claude Sonnet 4.5)  
âœ… **4 K Model Entegrasyonu** (GPT-3.5, GPT-4o-mini, Claude Haiku, Gemini)  
âœ… **User Evaluation System**  
âœ… **2-Stage Judge System** (GPT-4o)  
âœ… **ChromaDB HafÄ±za**  
âœ… **Comprehensive Logging**  
âœ… **CLI Testing Interface**  
âœ… **Docker Infrastructure**  

**Sonraki adÄ±m:** Phase 2 - Frontend UI ğŸš€

---

**BaÅŸarÄ±lar!** ğŸ’ª