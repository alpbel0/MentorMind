# MentorMind - Phase 1 MVP Roadmap

**Proje:** MentorMind - AI Evaluator Training System  
**Phase:** 1 - MVP (Minimum Viable Product)  
**Hedef:** Temel sistemin Ã§alÄ±ÅŸÄ±r hale getirilmesi  
**Tahmini SÃ¼re:** 4 hafta  
**BaÅŸlangÄ±Ã§:** 27 Ocak 2025  

---

## ğŸ“‹ Ä°Ã§indekiler

- [Phase 1 Overview](#-phase-1-overview)
- [Week 1: Database & Infrastructure](#-week-1-database--infrastructure)
- [Week 2: Question Generation & K Models](#-week-2-question-generation--k-models)
- [Week 3: User Evaluation & Judge Stage 1](#-week-3-user-evaluation--judge-stage-1)
- [Week 4: Judge Stage 2 & End-to-End Testing](#-week-4-judge-stage-2--end-to-end-testing)
- [Success Metrics](#-success-metrics)

---

## ğŸ¯ Phase 1 Overview

### Scope

**Dahil:**
- PostgreSQL database (5 tablo)
- Docker infrastructure
- Claude API soru Ã¼retimi
- 4 K model entegrasyonu (GPT-3.5, GPT-4o-mini, Claude Haiku, Gemini Flash)
- User evaluation API
- GPT-4o judge (2-stage)
- ChromaDB hafÄ±za sistemi
- Comprehensive logging
- CLI testing interface

**HariÃ§:**
- Frontend UI
- Multi-user support
- Advanced analytics
- Production deployment

### Definition of Done

Phase 1 tamamlanmÄ±ÅŸ sayÄ±lÄ±r eÄŸer:
- [ ] TÃ¼m database tablolarÄ± oluÅŸturuldu
- [ ] Docker container'lar Ã§alÄ±ÅŸÄ±yor
- [ ] Claude ile soru Ã¼retilebiliyor
- [ ] 4 K model soru cevaplayabiliyor
- [ ] KullanÄ±cÄ± deÄŸerlendirmesi kaydedilebiliyor
- [ ] Judge 2-stage workflow Ã§alÄ±ÅŸÄ±yor
- [ ] ChromaDB hafÄ±za aktif
- [ ] CLI Ã¼zerinden end-to-end test baÅŸarÄ±lÄ±
- [ ] Documentation gÃ¼ncel

---

## ğŸ“… Week 1: Database & Infrastructure

**Tarih:** 27 Ocak - 2 Åubat 2025  
**Hedef:** Database, Docker, logging altyapÄ±sÄ±

---

### Task 1.1: Project Setup

**Tahmini SÃ¼re:** 2 saat

**Durum:** âœ… **TAMAMLANDI** (26 Ocak 2025)

**YapÄ±lacaklar:**
- [x] GitHub repository oluÅŸtur
- [x] Ana klasÃ¶r yapÄ±sÄ±nÄ± oluÅŸtur:
  ```
  mentormind/
  â”œâ”€â”€ backend/
  â”œâ”€â”€ data/
  â”œâ”€â”€ chroma_data/
  â”œâ”€â”€ .gitignore
  â”œâ”€â”€ .env.example
  â”œâ”€â”€ README.md
  â””â”€â”€ ROADMAP.md
  ```
- [x] `.gitignore` dosyasÄ± ekle
- [x] Initial commit yap (commit: 3bf9c3b)

---

### Task 1.2: Environment Configuration

**Tahmini SÃ¼re:** 1 saat

**Durum:** âœ… **TAMAMLANDI** (26 Ocak 2025)

**YapÄ±lacaklar:**
- [x] `.env.example` oluÅŸtur (tÃ¼m environment variables ile)
- [x] `.env` dosyasÄ± oluÅŸtur
- [x] API key'leri ekle:
  - [x] ANTHROPIC_API_KEY
  - [x] OPENAI_API_KEY
  - [x] GOOGLE_API_KEY
- [x] Database credentials ayarla
- [x] `.env` dosyasÄ±nÄ±n `.gitignore`'da olduÄŸunu doÄŸrula

---

### Task 1.3: Docker Setup

**Tahmini SÃ¼re:** 3 saat

**Durum:** âœ… **TAMAMLANDI** (26 Ocak 2025)

**YapÄ±lacaklar:**
- [x] `Dockerfile` oluÅŸtur (Python 3.11-slim base image)
- [x] `docker-compose.yml` oluÅŸtur (3 service: backend, postgres, chromadb)
- [x] `.dockerignore` oluÅŸtur
- [x] `requirements.txt` oluÅŸtur (dependency conflict fixed: pytest==7.4.4)
- [x] `docker-compose build` ile build al
- [x] `docker-compose up -d` ile container'larÄ± baÅŸlat
- [x] `docker-compose ps` ile durumlarÄ± kontrol et
- [x] `curl http://localhost:8000` ile backend'e eriÅŸimi test et

**Notlar:**
- pytest 8.0.0 ve pytest-asyncio 0.23.4 arasÄ± conflict Ã§Ã¶zÃ¼ldÃ¼ (pytest downgrade edildi)
- env_file directive eklendi (.env dosyasÄ±ndan otomatik okuma)
- Environment variables docker-compose'a taÅŸÄ±ndÄ±

---

### Task 1.4: Python Backend Foundation

**Tahmini SÃ¼re:** 2 saat

**Durum:** âœ… **TAMAMLANDI** (26 Ocak 2025)

**YapÄ±lacaklar:**
- [x] `backend/requirements.txt` oluÅŸtur (Task 1.3'te yapÄ±ldÄ±)
- [x] Backend klasÃ¶r yapÄ±sÄ±nÄ± oluÅŸtur:
  ```
  backend/
  â”œâ”€â”€ config/
  â”œâ”€â”€ middleware/
  â”œâ”€â”€ models/
  â”œâ”€â”€ routers/
  â”œâ”€â”€ schemas/
  â”œâ”€â”€ scripts/
  â”œâ”€â”€ services/
  â”œâ”€â”€ prompts/
  â”œâ”€â”€ tests/
  â””â”€â”€ main.py
  ```
- [x] `backend/config/settings.py` oluÅŸtur (environment loader with Pydantic Settings)
- [x] `backend/config/__init__.py` oluÅŸtur
- [x] `backend/main.py` oluÅŸtur (minimal FastAPI app with 4 endpoints)
- [x] `backend/__init__.py` oluÅŸtur
- [x] FastAPI app'in Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± test et
- [x] Hot-reload aktif (--reload flag)

**Endpoints:**
- `GET /` - Root endpoint (API info)
- `GET /health` - Basic health check
- `GET /health/detailed` - Detailed system status
- `GET /info` - Development-only config info

**Swagger UI:** http://localhost:8000/docs
**ReDoc:** http://localhost:8000/redoc

---

### Task 1.5: Database Models - SQLAlchemy Setup

**Tahmini SÃ¼re:** 2 saat

**Durum:** âœ… **TAMAMLANDI** (26 Ocak 2026)

**YapÄ±lacaklar:**
- [x] `backend/models/database.py` oluÅŸtur:
  - [x] SQLAlchemy Base
  - [x] Database engine
  - [x] SessionLocal
  - [x] get_db() dependency
- [x] `backend/config/database.py` oluÅŸtur (DB connection config)
- [x] Database connection'Ä± test et

**Notlar:**
- SQLAlchemy 2.0 text() fonksiyonu kullanÄ±ldÄ± (raw SQL iÃ§in)
- Connection pool: pool_size=3, max_overflow=5
- Health endpoint'leri database status ile gÃ¼ncellendi
- Test script: `backend/scripts/test_db_connection.py`

---

### Task 1.6: SQL Schema - question_prompts

**Tahmini SÃ¼re:** 1 saat

**Durum:** âœ… **TAMAMLANDI** (26 Ocak 2026)

**YapÄ±lacaklar:**
- [x] `backend/schemas/01_question_prompts.sql` oluÅŸtur
- [x] Tablo tanÄ±mÄ±nÄ± yaz (id, primary_metric, bonus_metrics, question_type, user_prompt, golden_examples, difficulty, category_hints JSONB, timestamps)
- [x] UNIQUE constraint ekle (primary_metric, question_type)
- [x] Indexes ekle (primary_metric, difficulty)

---

### Task 1.7: SQL Schema - questions

**Tahmini SÃ¼re:** 1 saat

**Durum:** âœ… **TAMAMLANDI** (26 Ocak 2026)

**YapÄ±lacaklar:**
- [x] `backend/schemas/02_questions.sql` oluÅŸtur
- [x] Tablo tanÄ±mÄ±nÄ± yaz (id, question, category, reference_answer (nullable), expected_behavior (nullable), rubric_breakdown, denormalized fields, usage tracking)
- [x] Foreign key ekle (question_prompt_id nullable)
- [x] Indexes ekle (primary_metric, category, times_used, pool_selection composite)

---

### Task 1.8: SQL Schema - model_responses

**Tahmini SÃ¼re:** 1 saat

**Durum:** âœ… **TAMAMLANDI** (26 Ocak 2026)

**YapÄ±lacaklar:**
- [x] `backend/schemas/03_model_responses.sql` oluÅŸtur
- [x] Tablo tanÄ±mÄ±nÄ± yaz (id, question_id, model_name, response_text, evaluated, evaluation_id)
- [x] Foreign key ekle (question_id)
- [x] UNIQUE constraint ekle (question_id, model_name)
- [x] Indexes ekle (question_id, model_name, evaluated, pending_evaluations partial)

---

### Task 1.9: SQL Schema - user_evaluations

**Tahmini SÃ¼re:** 1 saat

**Durum:** âœ… **TAMAMLANDI** (26 Ocak 2026)

**YapÄ±lacaklar:**
- [x] `backend/schemas/04_user_evaluations.sql` oluÅŸtur
- [x] Tablo tanÄ±mÄ±nÄ± yaz (id, response_id, evaluations JSONB, judged)
- [x] Foreign key ekle (response_id)
- [x] Indexes ekle (response_id, judged, created_at_desc)

---

### Task 1.10: SQL Schema - judge_evaluations

**Tahmini SÃ¼re:** 1 saat

**Durum:** âœ… **TAMAMLANDI** (26 Ocak 2026)

**YapÄ±lacaklar:**
- [x] `backend/schemas/05_judge_evaluations.sql` oluÅŸtur
- [x] Tablo tanÄ±mÄ±nÄ± yaz (id, user_evaluation_id, independent_scores, alignment_analysis, judge_meta_score, overall_feedback, improvement_areas, positive_feedback, vector_context, primary_metric, gaps)
- [x] Foreign key ekle (user_evaluation_id)
- [x] CHECK constraint ekle (judge_meta_score BETWEEN 1 AND 5)
- [x] Indexes ekle (user_evaluation_id, meta_score, primary_metric, created_at_desc, metric_score composite)

---

### Task 1.11: SQLAlchemy Models

**Tahmini SÃ¼re:** 3 saat

**Durum:** âœ… **TAMAMLANDI** (26 Ocak 2026)

**YapÄ±lacaklar:**
- [x] `backend/models/question_prompt.py` oluÅŸtur (QuestionPrompt model)
- [x] `backend/models/question.py` oluÅŸtur (Question model)
- [x] `backend/models/model_response.py` oluÅŸtur (ModelResponse model)
- [x] `backend/models/user_evaluation.py` oluÅŸtur (UserEvaluation model)
- [x] `backend/models/judge_evaluation.py` oluÅŸtur (JudgeEvaluation model)
- [x] `backend/models/__init__.py` oluÅŸtur (tÃ¼m modelleri export et)

---

### Task 1.12: Pydantic Schemas

**Tahmini SÃ¼re:** 3 saat

**Durum:** âœ… **TAMAMLANDI** (26 Ocak 2026)

**YapÄ±lacaklar:**
- [x] `backend/models/schemas.py` oluÅŸtur
- [x] QuestionPrompt schemas (Base, Create, Response)
- [x] Question schemas (Base, Create, Response)
- [x] ModelResponse schemas (Base, Create, Response)
- [x] UserEvaluation schemas (Base, Create, Response)
- [x] JudgeEvaluation schemas (Base, Create, Response)
- [x] Validation logic ekle

---

### Task 1.13: Database Initialization Script

**Tahmini SÃ¼re:** 2 saat

**Durum:** âœ… **TAMAMLANDI** (26 Ocak 2026)

**YapÄ±lacaklar:**
- [x] `backend/scripts/init_db.py` oluÅŸtur
- [x] TÃ¼m SQL schema dosyalarÄ±nÄ± okuma logic'i ekle
- [x] SÄ±rayla execute et (01 â†’ 05)
- [x] Error handling ekle
- [x] Script'i test et: `docker-compose exec backend python scripts/init_db.py`
- [x] TablolarÄ± kontrol et: `docker-compose exec postgres psql -U mentormind -d mentormind -c "\dt"`

---

### Task 1.14: Logging Infrastructure

**Tahmini SÃ¼re:** 3 saat

**Durum:** âœ… **TAMAMLANDI** (29 Ocak 2026)

**YapÄ±lacaklar:**
- [x] `backend/config/logging_config.py` oluÅŸtur:
  - [x] Log formatters (default, detailed)
  - [x] Handlers (console, file, error_file)
  - [x] Loggers (mentormind, root)
  - [x] RotatingFileHandler (10MB, 5 backups)
- [x] `backend/services/llm_logger.py` oluÅŸtur:
  - [x] LLMCallLogger class
  - [x] log_call() method (provider, model, purpose, tokens, duration, success)
  - [x] JSONL format
- [x] `backend/middleware/logging_middleware.py` oluÅŸtur:
  - [x] RequestLoggingMiddleware class
  - [x] Request/Response logging
  - [x] Duration tracking
- [x] `backend/main.py`'a logging ekle
- [x] Test: `curl http://localhost:8000` ve loglarÄ± kontrol et

**Notlar:**
- 3 log dosyasÄ± oluÅŸturuluyor: mentormind.log, errors.log, llm_calls.jsonl
- Log dosyalarÄ± 10MB'da rotate olur, 5 backup tutar
- Request logging middleware tÃ¼m HTTP request'leri loglar

---

### Task 1.15: Health Check Endpoints

**Tahmini SÃ¼re:** 2 saat

**Durum:** âœ… **TAMAMLANDI** (29 Ocak 2026)

**YapÄ±lacaklar:**
- [x] `backend/routers/health.py` oluÅŸtur
- [x] `GET /api/health` endpoint (basic health)
- [x] `GET /api/health/detailed` endpoint:
  - [x] Database connection check
  - [x] ChromaDB connection check
  - [x] Status response (healthy/degraded)
- [x] `backend/main.py`'a router'Ä± ekle
- [x] Test: `curl http://localhost:8000/api/health`
- [x] Test: `curl http://localhost:8000/api/health/detailed`

**Notlar:**
- Implementation done directly in main.py (no separate router needed)
- Database connection testing working
- Latency measurement working
- Pool status reporting working

---

### Task 1.16: Testing Infrastructure

**Tahmini SÃ¼re:** 2 saat

**Durum:** âœ… **TAMAMLANDI** (29 Ocak 2026)

**YapÄ±lacaklar:**
- [x] `backend/tests/conftest.py` oluÅŸtur:
  - [x] Test database setup (PostgreSQL: mentormind_test)
  - [x] db fixture
  - [x] client fixture (TestClient)
- [x] `backend/pytest.ini` oluÅŸtur
- [x] `backend/tests/test_health.py` oluÅŸtur (Ã¶rnek test)
- [x] Tests Ã§alÄ±ÅŸtÄ±r: `docker-compose exec backend pytest`
- [x] Coverage report kontrol et

**Notlar:**
- PostgreSQL test database kullanÄ±lÄ±yor (SQLite deÄŸil)
- SQLAlchemy create_all() ENUM ve Trigger'larÄ± oluÅŸturamaz, bu yÃ¼zden ham SQL dosyalarÄ± sÄ±rayla Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor
- 5 test geÃ§iyor (test_health.py)
- Test coverage: 46% (backend genel)

---

### Task 1.17: Seed Data Script (Skeleton)

**Tahmini SÃ¼re:** 1 saat

**Durum:** âœ… **TAMAMLANDI** (29 Ocak 2026)

**YapÄ±lacaklar:**
- [x] `backend/scripts/seed_data.py` oluÅŸtur
- [x] seed_question_prompts() fonksiyonu (skeleton, Week 2'de doldurulacak)
- [x] verify_prompts() fonksiyonu
- [x] reset_prompts() fonksiyonu
- [x] main() fonksiyonu (CLI with --verify, --reset, --dry-run flags)
- [x] Error handling
- [x] Script Ã§alÄ±ÅŸtÄ±rÄ±labilir durumda (skeleton mode)

**Notlar:**
- CLI flags: `--verify` (mevcut promptlarÄ± kontrol et), `--reset` (tÃ¼m promptlarÄ± sil), `--dry-run` (ne yapÄ±lacaÄŸÄ±nÄ± gÃ¶ster)
- Normal mode: Week 2'de 24 ÅŸablon eklenecek (8 metrik Ã— 3 zorluk)
- Exit code 1 when incomplete (expected behavior)

---

### Task 1.18: LLM Cost Analysis Script

**Tahmini SÃ¼re:** 1 saat

**YapÄ±lacaklar:**
- [ ] `backend/scripts/analyze_llm_costs.py` oluÅŸtur
- [ ] JSONL log okuma logic'i
- [ ] Provider/model bazÄ±nda grouping
- [ ] Ä°statistik hesaplama (calls, tokens, duration, est. cost)
- [ ] Pretty print output
- [ ] Script'i test et (boÅŸ log ile)

---

### âœ… Week 1 Checklist

- [x] Docker container'lar Ã§alÄ±ÅŸÄ±yor (backend, postgres, chromadb)
- [x] Database tablolarÄ± oluÅŸturuldu (5 tablo) (Completed: 26 Ocak 2026)
- [x] SQLAlchemy models hazÄ±r (Completed: 26 Ocak 2026)
- [x] Pydantic schemas hazÄ±r (Completed: 26 Ocak 2026)
- [x] Logging sistemi Ã§alÄ±ÅŸÄ±yor (3 log dosyasÄ±: mentormind.log, errors.log, llm_calls.jsonl) (Completed: 29 Ocak 2026)
- [x] Health check endpoints Ã§alÄ±ÅŸÄ±yor (Completed: 29 Ocak 2026)
- [x] Test infrastructure kurulu (Completed: 29 Ocak 2026)
- [ ] Scripts hazÄ±r (init_db.py, seed_data.py, analyze_llm_costs.py)

---

## ğŸ“… Week 2: Question Generation & K Models

**Tarih:** 3 - 9 Åubat 2025  
**Hedef:** Soru Ã¼retimi ve K model entegrasyonu

---

 ### Task 2.1: Master Question Prompts & Golden Examples Preparation

**Tahmini SÃ¼re:** 4 saat

**Durum:** âœ… **TAMAMLANDI** (30 Ocak 2026)

**AÃ§Ä±klama:** 24 ayrÄ± prompt yazmak yerine, her metrik iÃ§in 1 adet "Master Prompt" hazÄ±rlanacak. Ã‡eÅŸitlilik
      veritabanÄ±ndaki `question_type` deÄŸiÅŸkeni ve o tipe Ã¶zel `golden_examples` (few-shot) ile saÄŸlanacak.

**YapÄ±lacaklar:**
- [x] 8 metrik iÃ§in dinamik "Master Prompt" ÅŸablonlarÄ±nÄ± oluÅŸtur.
- [x] 24 farklÄ± `question_type` senaryosu iÃ§in kaliteli "Golden Examples" verilerini hazÄ±rla.

**Metrik GruplarÄ± (Her biri 1 Master Prompt + 3 Tip Ã–rnek):**
- [x] **Truthfulness:** (hallucination_test, factual_accuracy, edge_case)
- [x] **Clarity:** (explain_like_5, technical_jargon, step_by_step)
- [x] **Safety:** (harmful_content, medical_advice, illegal_activity)
- [x] **Bias:** (stereotype_check, implicit_bias, fairness_test)
- [x] **Helpfulness:** (practical_guidance, example_provision, actionable_advice)
- [x] **Consistency:** (multi_part_question, repeated_query, contradiction_check)
- [x] **Efficiency:** (concise_explanation, time_complexity, resource_optimization)
- [x] **Robustness:** (edge_case, adversarial_input, stress_test)

---

### Task 2.2: Seed Data Implementation

**Tahmini SÃ¼re:** 2 saat

**Durum:** âœ… **TAMAMLANDI** (30 Ocak 2026)

**YapÄ±lacaklar:**
- [x] `backend/scripts/seed_data.py`'daki seed_question_prompts() fonksiyonunu tamamla
- [x] promptlar'u dictionary formatÄ±nda ekle
- [x] bonus_metrics'i belirle (her primary metric iÃ§in 2 bonus)
- [x] difficulty ve category_hint ekle
- [x] Script'i Ã§alÄ±ÅŸtÄ±r: `docker-compose exec backend python scripts/seed_data.py`
- [x] Database'i kontrol et: `SELECT COUNT(*) FROM question_prompts;` (24 kayÄ±t doÄŸrulandÄ±) 

---

### Task 2.3: Claude Service - Setup

**Tahmini SÃ¼re:** 2 saat

**Durum:** âœ… **TAMAMLANDI** (30 Ocak 2026)

**YapÄ±lacaklar:**
- [x] `backend/services/claude_service.py` oluÅŸtur
- [x] Anthropic client initialize et
- [x] API key'i environment'tan al
- [x] Basic error handling ekle
- [x] Logger setup
- [x] `claude_api_timeout` configuration (settings.py)

---

### Task 2.4: Claude Service - Dynamic Category Selection

**Tahmini Sure:** 2 saat (Mantik genisletildi)

**Durum:** TAMAMLANDI (30 Ocak 2026)

**Aciklama:** Soru kategorilerini 4 ana baslikla sinirlamak yerine, veritabanindaki `category_hints`
  alanina tam uyum saglayan ve "any" durumunda genis bir yelpazeden secim yapan dinamik bir yapilandi.

**Yapilacaklar:**
- [x] `backend/services/claude_service.py` icinde genis kapsamli bir `DEFAULT_CATEGORY_POOL` (21 kategori) tanimlandi.
- [x] `select_category(category_hints: list[str]) -> str` fonksiyonu yazildi:
  - [x] Eger `category_hints` ozel konular iceriyorsa (orn: `["React", "SQL"]`), bunlardan birini sec.
  - [x] Eger `category_hints` `["any"]` iceriyorsa veya bossa, `DEFAULT_CATEGORY_POOL`'dan rastgele sec.
  - [x] Legacy category mapping (Math->Mathematics, Coding->Programming, vb.) eklendi.
- [x] `backend/services/__init__.py` export'lari guncellendi.

**Notlar:**
- 21 kategorilik DEFAULT_CATEGORY_POOL olusturuldu (Akademik, Teknoloji, Profesyonel, Sanat)
- Legacy kategoriler (Math, Coding, Medical, General) yeni kategorilere map edildi


### Task 2.5: Claude Service - Prompt Template

**Tahmini SÃ¼re:** 2 saat

**Durum:** âœ… **TAMAMLANDI** (30 Ocak 2026 - Kod analizi ile tespit edildi)

**AÃ§Ä±klama:** `render_user_prompt()` fonksiyonu `backend/prompts/master_prompts.py` dosyasÄ±nda uygulanmÄ±ÅŸ durumda. Fonksiyon template'taki placeholder'larÄ± doldurur ve tam prompt dÃ¶ndÃ¼rÃ¼r.

**YapÄ±lacaklar:**
- [x] `render_user_prompt(primary_metric, question_type, category, difficulty) -> str` fonksiyonu mevcut (master_prompts.py:947)
- [x] Template render et (user_prompt'ta placeholder'larÄ± replace)
- [x] Golden examples formatla (format_golden_example fonksiyonu mevcut)
- [x] Return full prompt

---

### Task 2.6: Claude Service - Question Generation

**Tahmini SÃ¼re:** 3 saat

**Durum:** âœ… **TAMAMLANDI** (30 Ocak 2026 - Kod analizi ile tespit edildi + Model gÃ¼ncellendi)

**AÃ§Ä±klama:** `_generate_new_question()` ve `generate_question()` fonksiyonlarÄ± `backend/services/claude_service.py` dosyasÄ±nda uygulanmÄ±ÅŸ durumda. Model gÃ¼ncellemesi yapÄ±ldÄ±.

**YapÄ±lacaklar:**
- [x] `generate_question(primary_metric: str, use_pool: bool) -> Question` fonksiyonu mevcut (claude_service.py:407)
  - [x] use_pool=True ise havuzdan seÃ§ (_select_from_pool fonksiyonu mevcut)
  - [x] use_pool=False ise yeni Ã¼ret (_generate_new_question fonksiyonu mevcut)
- [x] Yeni Ã¼retim logic'i:
  - [x] question_prompts'tan random seÃ§ (WHERE primary_metric=?)
  - [x] Category belirle (select_category fonksiyonu mevcut)
  - [x] Prompt render et (render_user_prompt ile master_prompts'dan alÄ±yor)
  - [x] Claude API'ya gÃ¶nder (claude-haiku-4-5-20251001 - YENÄ° MODEL!)
  - [x] Response parse et (JSON)
  - [x] Question object oluÅŸtur (ID: q_YYYYMMDD_HHMMSS_randomhex)
  - [x] Database'e kaydet
- [x] LLM call logging ekle (log_llm_call ile loglanÄ±yor)
- [x] Error handling (timeout, invalid JSON, API error)

---

### Task 2.7: Claude Service - Response Parsing

**Tahmini SÃ¼re:** 2 saat

**Durum:** âœ… **TAMAMLANDI** (30 Ocak 2026 - Kod analizi ile tespit edildi)

**AÃ§Ä±klama:** `_parse_claude_response()` ve `_parse_json()` fonksiyonlarÄ± `backend/services/claude_service.py` dosyasÄ±nda uygulanmÄ±ÅŸ durumuda. Markdown code block iÃ§indeki JSON'Ä± Ã§Ä±karabilir.

**YapÄ±lacaklar:**
- [x] `_parse_claude_response(content: str) -> dict` fonksiyonu mevcut (claude_service.py:343)
- [x] Expected fields validate et:
  - [x] question (str)
  - [x] reference_answer (str)
  - [x] expected_behavior (str)
  - [x] rubric_breakdown (dict: 1-5 â†’ descriptions)
- [x] Validation errors handle et (ValueError fÄ±rlatÄ±yor)
- [x] Return parsed data

---

### Task 2.8: Claude Service - Tests

**Tahmini SÃ¼re:** 2 saat

**Durum:** âœ… **TAMAMLANDI** (30 Ocak 2026 - CanlÄ± API testleri yazÄ±ldÄ±)

**AÃ§Ä±klama:** `backend/tests/test_claude_service.py` oluÅŸturuldu. Unit testler ve canlÄ± API testleri (mock yok) iÃ§eriyor.

**YapÄ±lacaklar:**
- [x] `backend/tests/test_claude_service.py` oluÅŸtur
- [x] test_select_category() (all category_hint variations)
- [x] test_parse_claude_response() (valid JSON, markdown, invalid)
- [x] test_claude_service_initialization() (model check)
- [x] test_generate_question_live_api() (CANLI API - gerÃ§ek Claude Ã§aÄŸrÄ±sÄ±)
- [x] Tests Ã§alÄ±ÅŸtÄ±r

---

### Task 2.9: K Model Service - Setup (OpenRouter Implementation)

**Tahmini SÃ¼re:** 2 saat

**Durum:** âœ… **TAMAMLANDI** (30 Ocak 2026)

**Not:** OpenRouter kullanÄ±larak 6 model entegrasyonu yapÄ±ldÄ±.

**YapÄ±lacaklar:**
- [x] `backend/services/model_service.py` oluÅŸtur
- [x] K_MODELS constant tanÄ±mla (6 model via OpenRouter):
  ```python
  K_MODELS = [
      "mistralai/mistral-nemo",
      "qwen/qwen-2.5-7b-instruct",
      "deepseek/deepseek-chat",
      "google/gemini-flash-1.5",
      "openai/gpt-4o-mini",
      "openai/gpt-3.5-turbo",
  ]
  ```
- [x] OpenAI client initialize et (base_url=https://openrouter.ai/api/v1)
- [x] Logger setup

---

### Task 2.10: K Model Service - Model Selection

**Tahmini SÃ¼re:** 2 saat

**Durum:** âœ… **TAMAMLANDI** (30 Ocak 2026)

**YapÄ±lacaklar:**
- [x] `select_model(question_id: str, db: Session) -> str` fonksiyonu yaz:
  - [x] Bu soruyu hangi modeller cevapladÄ±? (query model_responses)
  - [x] CevaplamamÄ±ÅŸ modeller listele
  - [x] EÄŸer tÃ¼mÃ¼ cevaplamÄ±ÅŸ â†’ random seÃ§
  - [x] EÄŸer bazÄ±larÄ± cevaplamamÄ±ÅŸ â†’ onlardan random seÃ§
- [x] Test fonksiyonu

---

### Task 2.11: K Model Service - OpenRouter Integration

**Tahmini SÃ¼re:** 2 saat

**Durum:** âœ… **TAMAMLANDI** (30 Ocak 2026)

**Not:** OpenRouter unified API gateway kullanÄ±ldÄ±.

**YapÄ±lacaklar:**
- [x] `_call_openrouter(model_name: str, question: str) -> str` fonksiyonu yaz
- [x] OpenAI client ile OpenRouter API call (base_url=https://openrouter.ai/api/v1)
- [x] Messages format: `[{"role": "user", "content": question}]`
- [x] Response parse et (choices[0].message.content)
- [x] LLM call logging ekle
- [x] Error handling
- [x] Test (mock API)

---

### Task 2.12: K Model Service - (Skipped - Merged into 2.11)

**Tahmini SÃ¼re:** 2 saat

**Durum:** â­ï¸ **ATLANDI** (OpenRouter ile birleÅŸtirildi)

**Not:** OpenRouter sayesinde ayrÄ± Anthropic entegrasyonuna gerek kalmadÄ±.

---

### Task 2.13: K Model Service - (Skipped - Merged into 2.11)

**Tahmini SÃ¼re:** 2 saat

**Durum:** â­ï¸ **ATLANDI** (OpenRouter ile birleÅŸtirildi)

**Not:** OpenRouter sayesinde ayrÄ± Google entegrasyonuna gerek kalmadÄ±.

---

### Task 2.14: K Model Service - Unified Interface

**Tahmini SÃ¼re:** 2 saat

**Durum:** âœ… **TAMAMLANDI** (30 Ocak 2026)

**YapÄ±lacaklar:**
- [x] `answer_question(question_id: str, model_name: str, db: Session) -> ModelResponse` fonksiyonu yaz:
  - [x] Question'Ä± database'den getir
  - [x] OpenRouter API call yap (_call_openrouter)
  - [x] ModelResponse object oluÅŸtur (ID: resp_YYYYMMDD_HHMMSS_randomhex)
  - [x] Database'e kaydet
  - [x] Return response
- [x] Error handling

---

### Task 2.15: K Model Service - Tests

**Tahmini SÃ¼re:** 2 saat

**Durum:** âœ… **TAMAMLANDI** (30 Ocak 2026)

**YapÄ±lacaklar:**
- [x] `backend/tests/test_model_service.py` oluÅŸtur
- [x] test_select_model()
- [x] test_call_openrouter() (mock)
- [x] test_answer_question() (mock)
- [x] Tests Ã§alÄ±ÅŸtÄ±r (11 passed)

---

### Task 2.16: Questions Router - Setup

**Tahmini SÃ¼re:** 1 saat

**Durum:** âœ… **TAMAMLANDI** (30 Ocak 2026)

**YapÄ±lacaklar:**
- [x] `backend/routers/questions.py` oluÅŸtur
- [x] APIRouter oluÅŸtur
- [x] Logger setup

---

### Task 2.17: Questions Router - Generate Endpoint

**Tahmini SÃ¼re:** 3 saat

**Durum:** âœ… **TAMAMLANDI** (30 Ocak 2026)

**YapÄ±lacaklar:**
- [x] `POST /api/questions/generate` endpoint yaz:
  - [x] Request schema: `{primary_metric: str, use_pool: bool}`
  - [x] Claude service'i Ã§aÄŸÄ±r (generate_question)
  - [x] Model seÃ§ (select_model)
  - [x] Model service'i Ã§aÄŸÄ±r (answer_question)
  - [x] Response format: `{question_id, response_id, question, model_response, model_name, category}`
  - [x] Error handling
- [x] Pydantic request/response schemas
- [x] Test endpoint (integration test - manual curl successful)

---

### Task 2.18: Questions Router - Pool Stats Endpoint

**Tahmini SÃ¼re:** 2 saat

**Durum:** âœ… **TAMAMLANDI** (30 Ocak 2026)

**YapÄ±lacaklar:**
- [x] `GET /api/questions/pool/stats` endpoint yaz:
  - [x] Total questions count
  - [x] By metric breakdown
  - [x] By category breakdown
  - [x] By difficulty breakdown
  - [x] Average times_used
- [x] Response schema
- [x] Test endpoint (curl successful)

---

### Task 2.19: Router Integration

**Tahmini SÃ¼re:** 1 saat

**Durum:** âœ… **TAMAMLANDI** (30 Ocak 2026)

**YapÄ±lacaklar:**
- [x] `backend/main.py`'a questions router'Ä± ekle
- [x] Prefix: `/api/questions`
- [x] Tags: `["questions"]`
- [x] Test: `curl -X POST http://localhost:8000/api/questions/generate -d '{"primary_metric": "Truthfulness", "use_pool": false}'`

---

### Task 2.20: End-to-End Test (Week 2)

**Tahmini SÃ¼re:** 2 saat

**Durum:** âœ… **TAMAMLANDI** (30 Ocak 2026)

**YapÄ±lacaklar:**
- [x] Manuel test senaryosu Ã§alÄ±ÅŸtÄ±r:
  1. [x] Seed data yÃ¼kle (24 prompts)
  2. [x] Yeni soru Ã¼ret (Truthfulness) - BaÅŸarÄ±lÄ±
  3. [x] K model cevapladÄ± (mistralai/mistral-nemo)
  4. [x] Pool stats kontrol et - BaÅŸarÄ±lÄ±
  5. [x] Database'de question ve model_response kayÄ±tlarÄ±nÄ± kontrol et
- [x] LoglarÄ± incele (mentormind.log, llm_calls.jsonl) - Her ÅŸey loglanÄ±yor
- [x] Bug'larÄ± tespit et ve fix'le

---

### âœ… Week 2 Checklist

- [x] 24 question_prompt seeded (30 Ocak 2026)
- [x] Claude service soru Ã¼retebiliyor (Ã–nceki tasks'te yapÄ±ldÄ±)
- [x] 6 K model soru cevaplayabiliyor (30 Ocak 2026)
- [x] Question pool sistemi Ã§alÄ±ÅŸÄ±yor
- [x] API endpoints Ã§alÄ±ÅŸÄ±yor (generate, pool stats)
- [x] LLM call logging aktif
- [ ] Integration tests geÃ§iyor

---

## ğŸ“… Week 3: User Evaluation & Judge Stage 1

**Tarih:** 10 - 16 Åubat 2025  
**Hedef:** User evaluation API ve judge'Ä±n independent evaluation'Ä±

---

### Task 3.1: Evaluation Router - Setup

**Tahmini SÃ¼re:** 1 saat

**Durum:** âœ… **TAMAMLANDI** (30 Ocak 2026)

**YapÄ±lacaklar:**
- [x] `backend/routers/evaluations.py` oluÅŸtur
- [x] APIRouter oluÅŸtur
- [x] Logger setup

---

### Task 3.2: Evaluation Schemas

**Tahmini SÃ¼re:** 2 saat

**Durum:** âœ… **TAMAMLANDI** (30 Ocak 2026)

**YapÄ±lacaklar:**
- [x] `backend/models/schemas.py`'ye ekle:
  - [x] MetricEvaluation schema (score: 1-5 or null, reasoning: str)
  - [x] EvaluationSubmitRequest schema (response_id, evaluations: Dict[str, MetricEvaluation])
  - [x] EvaluationSubmitResponse schema (evaluation_id, status, message)
- [x] Validation logic:
  - [x] 8 metrik olmalÄ±
  - [x] Score 1-5 veya null
  - [x] Reasoning required if score given

---

### Task 3.3: Evaluation Submit Endpoint

**Tahmini SÃ¼re:** 3 saat

**Durum:** âœ… **TAMAMLANDI** (30 Ocak 2026)

**YapÄ±lacaklar:**
- [x] `POST /api/evaluations/submit` endpoint yaz:
  - [x] Request validate et
  - [x] UserEvaluation object oluÅŸtur (ID: eval_YYYYMMDD_HHMMSS_randomhex)
  - [x] evaluations JSON'u serialize et
  - [x] Database'e kaydet
  - [ ] Async judge task baÅŸlat (arka planda) â†’ Task 3.11'de yapÄ±lacak
  - [x] Immediate response dÃ¶n: `{evaluation_id, status: "submitted", message}`
- [x] Error handling
- [x] Router integration (main.py)
- [x] Unit tests (test_evaluations.py)

---

### Task 3.4: Evaluation Update Endpoint

**Tahmini SÃ¼re:** 1 saat

**Durum:** âœ… **TAMAMLANDI** (30 Ocak 2026)

**Not:** Dairesel iliÅŸki (circular dependency) nedeniyle `evaluation_id` maddesi iptal edildi, diÄŸer iÅŸlemler Task 3.3 ile birleÅŸtirildi.

**YapÄ±lacaklar:**
- [x] model_responses tablosunda evaluated flag'i update et
- [x] evaluation_id'yi set et (iptal - circular dependency)
- [x] Endpoint Ã§aÄŸrÄ±sÄ±nda bu update'i yap (Task 3.3'te yapÄ±ldÄ±)

---

### Task 3.5: Judge Prompts - Hardcoded

**Tahmini SÃ¼re:** 3 saat

**YapÄ±lacaklar:**
- [ ] `backend/prompts/judge_prompts.py` oluÅŸtur
- [ ] JUDGE_PROMPTS dictionary:
  - [ ] "independent" key:
    - [ ] system_prompt
    - [ ] user_prompt_template (placeholders: {question}, {model_name}, {model_response}, {reference_answer}, {expected_behavior}, {rubric_breakdown})
  - [ ] "mentoring" key:
    - [ ] system_prompt
    - [ ] user_prompt_template
- [ ] Prompt'larÄ± yaz (detaylÄ±, net instruction'lar)

---

### Task 3.6: Judge Service - Setup

**Tahmini SÃ¼re:** 1 saat

**YapÄ±lacaklar:**
- [ ] `backend/services/judge_service.py` oluÅŸtur
- [ ] OpenAI client initialize et (GPT-4o iÃ§in)
- [ ] Logger setup
- [ ] Import judge_prompts

---

### Task 3.7: Judge Service - Data Fetching

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `fetch_evaluation_data(user_eval_id: str) -> dict` fonksiyonu yaz:
  - [ ] user_evaluation getir
  - [ ] model_response getir (response_id Ã¼zerinden)
  - [ ] question getir (question_id Ã¼zerinden)
  - [ ] Return: `{user_eval, model_response, question, user_scores: dict}`
- [ ] Test fonksiyonu

---

### Task 3.8: Judge Service - Stage 1 Implementation

**Tahmini SÃ¼re:** 4 saat

**YapÄ±lacaklar:**
- [ ] `stage1_independent_evaluation(user_eval_id: str) -> dict` fonksiyonu yaz:
  - [ ] Evaluation data fetch et
  - [ ] Prompt render et (judge_prompts["independent"])
  - [ ] Placeholders replace et
  - [ ] GPT-4o'ya gÃ¶nder
  - [ ] Response parse et (JSON)
  - [ ] Validate: 8 metrik, her biri {score, rationale}
  - [ ] Return independent_scores dict
- [ ] LLM call logging ekle
- [ ] Error handling (timeout, invalid JSON)

---

### Task 3.9: Judge Service - Response Parsing

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `parse_judge_response(response: str) -> dict` fonksiyonu yaz
- [ ] JSON parse et
- [ ] Validate structure
- [ ] Handle errors (malformed JSON)
- [ ] Return parsed dict

---

### Task 3.10: Async Task Infrastructure - Setup

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `backend/tasks/__init__.py` oluÅŸtur
- [ ] `backend/tasks/judge_task.py` oluÅŸtur
- [ ] Background task decorator kullan (FastAPI BackgroundTasks)
- [ ] Logger setup

---

### Task 3.11: Async Task - Judge Task

**Tahmini SÃ¼re:** 3 saat

**YapÄ±lacaklar:**
- [ ] `run_judge_evaluation(user_eval_id: str)` async fonksiyonu yaz:
  - [ ] Try/except wrapper
  - [ ] Stage 1 Ã§aÄŸÄ±r
  - [ ] (Stage 2 Week 4'te eklenecek)
  - [ ] user_evaluations.judged = TRUE set et
  - [ ] Errors handle et ve logla
- [ ] Task'Ä± evaluation submit endpoint'ten Ã§aÄŸÄ±r (BackgroundTasks)

---

### Task 3.12: Judge Feedback Endpoint - Basic

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `GET /api/evaluations/{evaluation_id}/feedback` endpoint yaz:
  - [ ] user_evaluation getir
  - [ ] judged flag kontrol et
  - [ ] EÄŸer FALSE â†’ return `{status: "processing"}`
  - [ ] EÄŸer TRUE â†’ judge_evaluation getir ve return
- [ ] Response schema
- [ ] Test endpoint

---

### Task 3.13: Judge Service - Tests

**Tahmini SÃ¼re:** 3 saat

**YapÄ±lacaklar:**
- [ ] `backend/tests/test_judge_service.py` oluÅŸtur
- [ ] test_fetch_evaluation_data()
- [ ] test_parse_judge_response()
- [ ] test_stage1_independent_evaluation() (mock GPT-4o)
- [ ] Tests Ã§alÄ±ÅŸtÄ±r

---

### Task 3.14: Integration Test (Week 3)

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] Manuel test senaryosu:
  1. [ ] Soru Ã¼ret ve K model cevapla
  2. [ ] User evaluation submit et (8 metrik)
  3. [ ] Judge task'Ä±n arka planda Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± loglardan kontrol et
  4. [ ] 10-30 saniye bekle
  5. [ ] Feedback endpoint'ten judge sonucunu al
  6. [ ] judge_evaluations tablosunu kontrol et
- [ ] Bug'larÄ± tespit et ve fix'le

---

### âœ… Week 3 Checklist

- [ ] User evaluation API Ã§alÄ±ÅŸÄ±yor
- [ ] Evaluation validation doÄŸru
- [ ] Judge prompts hazÄ±r (hardcoded)
- [ ] Judge Stage 1 (independent) Ã§alÄ±ÅŸÄ±yor
- [ ] Async task infrastructure kurulu
- [ ] Judge feedback endpoint Ã§alÄ±ÅŸÄ±yor
- [ ] LLM logging GPT-4o call'larÄ±nÄ± kaydediyor
- [ ] Integration tests geÃ§iyor

---

## ğŸ“… Week 4: Judge Stage 2 & End-to-End Testing

**Tarih:** 17 - 23 Åubat 2025  
**Hedef:** ChromaDB entegrasyonu, judge Stage 2, end-to-end test

---

### Task 4.1: ChromaDB Service - Setup

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `backend/services/chromadb_service.py` oluÅŸtur
- [ ] ChromaDB client initialize et
- [ ] Collection oluÅŸtur ("evaluation_memory")
- [ ] Embedding function setup (OpenAI text-embedding-3-small)
- [ ] Logger setup

---

### Task 4.2: ChromaDB Service - Add to Memory

**Tahmini SÃ¼re:** 3 saat

**YapÄ±lacaklar:**
- [ ] `add_to_memory(user_eval_id: str, judge_eval_id: str) -> None` fonksiyonu yaz:
  - [ ] Evaluation data fetch et
  - [ ] Judge evaluation fetch et
  - [ ] Document text oluÅŸtur (summary format)
  - [ ] Metadata oluÅŸtur:
    - evaluation_id
    - judge_id
    - category
    - primary_metric
    - judge_meta_score
    - alignment_gap
    - mistake_pattern
    - timestamp
  - [ ] ChromaDB'ye add et
- [ ] Error handling
- [ ] Test fonksiyonu

---

### Task 4.3: ChromaDB Service - Query Past Mistakes

**Tahmini SÃ¼re:** 3 saat

**YapÄ±lacaklar:**
- [ ] `query_past_mistakes(primary_metric: str, category: str, n: int = 5) -> dict` fonksiyonu yaz:
  - [ ] Query text oluÅŸtur: "User evaluating {primary_metric} in {category} category"
  - [ ] ChromaDB query (where filter: primary_metric & category)
  - [ ] n_results=5
  - [ ] Return: `{ids, documents, metadatas, distances}`
- [ ] Empty result handling
- [ ] Error handling
- [ ] Test fonksiyonu

---

### Task 4.4: Judge Service - Comparison Table Generator

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `generate_comparison_table(user_scores: dict, judge_scores: dict) -> str` fonksiyonu yaz:
  - [ ] Markdown table oluÅŸtur
  - [ ] Columns: Metric, User Score, Judge Score, Gap, Verdict
  - [ ] Her 8 metrik iÃ§in satÄ±r
  - [ ] Gap hesapla (user - judge)
  - [ ] Verdict belirle (over_estimated, under_estimated, aligned, not_applicable)
  - [ ] Return markdown string
- [ ] Test fonksiyonu

---

### Task 4.5: Judge Service - Weighted Gap Calculation

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `calculate_weighted_gap(user_scores: dict, judge_scores: dict, primary_metric: str, bonus_metrics: list) -> float` fonksiyonu yaz:
  - [ ] Primary gap hesapla (abs)
  - [ ] Bonus gaps hesapla (avg)
  - [ ] Other gaps hesapla (avg)
  - [ ] Weighted gap: primary*0.7 + bonus*0.2 + other*0.1
  - [ ] Return weighted_gap
- [ ] Test fonksiyonu

---

### Task 4.6: Judge Service - Meta Score Mapping

**Tahmini SÃ¼re:** 1 saat

**YapÄ±lacaklar:**
- [ ] `weighted_gap_to_meta_score(weighted_gap: float) -> int` fonksiyonu yaz:
  - [ ] <= 0.5 â†’ 5
  - [ ] <= 1.0 â†’ 4
  - [ ] <= 1.5 â†’ 3
  - [ ] <= 2.0 â†’ 2
  - [ ] else â†’ 1
- [ ] Test fonksiyonu

---

### Task 4.7: Judge Service - Stage 2 Implementation

**Tahmini SÃ¼re:** 4 saat

**YapÄ±lacaklar:**
- [ ] `stage2_mentoring_comparison(user_eval_id: str, stage1_scores: dict, vector_context: dict) -> dict` fonksiyonu yaz:
  - [ ] Evaluation data fetch et
  - [ ] Question data getir (primary_metric, bonus_metrics)
  - [ ] Comparison table oluÅŸtur
  - [ ] User scores serialize et
  - [ ] Past mistakes formatla (vector_context'ten)
  - [ ] Prompt render et (judge_prompts["mentoring"])
  - [ ] Placeholders replace et
  - [ ] GPT-4o'ya gÃ¶nder
  - [ ] Response parse et
  - [ ] Weighted gap hesapla
  - [ ] Meta score hesapla
  - [ ] Return: alignment_analysis, judge_meta_score, overall_feedback, improvement_areas, positive_feedback, primary_metric_gap, weighted_gap
- [ ] LLM call logging
- [ ] Error handling

---

### Task 4.8: Judge Service - Full Flow Integration

**Tahmini SÃ¼re:** 3 saat

**YapÄ±lacaklar:**
- [ ] `full_judge_evaluation(user_eval_id: str) -> str` fonksiyonu yaz:
  - [ ] Stage 1: independent evaluation
  - [ ] ChromaDB: query past mistakes
  - [ ] Stage 2: mentoring comparison
  - [ ] Judge ID oluÅŸtur (judge_YYYYMMDD_HHMMSS_randomhex)
  - [ ] judge_evaluations'a kaydet
  - [ ] ChromaDB: add to memory
  - [ ] user_evaluations.judged = TRUE
  - [ ] Return judge_id
- [ ] Error handling (rollback on failure)

---

### Task 4.9: Async Task - Full Judge

**Tahmini SÃ¼re:** 1 saat

**YapÄ±lacaklar:**
- [ ] `backend/tasks/judge_task.py`'daki run_judge_evaluation() fonksiyonunu gÃ¼ncelle:
  - [ ] full_judge_evaluation() Ã§aÄŸÄ±r
  - [ ] Success/failure logla
- [ ] Test async task

---

### Task 4.10: Judge Feedback Endpoint - Complete

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] `GET /api/evaluations/{evaluation_id}/feedback` endpoint'i gÃ¼ncelle:
  - [ ] Complete response format:
    - evaluation_id
    - judge_meta_score
    - overall_feedback
    - alignment_analysis (full dict)
    - improvement_areas
    - positive_feedback
    - past_patterns_referenced (ChromaDB'den)
  - [ ] Response schema gÃ¼ncelle
- [ ] Test endpoint

---

### Task 4.11: Statistics Router - Setup

**Tahmini SÃ¼re:** 1 saat

**YapÄ±lacaklar:**
- [ ] `backend/routers/stats.py` oluÅŸtur
- [ ] APIRouter oluÅŸtur
- [ ] Logger setup

---

### Task 4.12: Statistics - Overview Endpoint

**Tahmini SÃ¼re:** 3 saat

**YapÄ±lacaklar:**
- [ ] `GET /api/stats/overview` endpoint yaz:
  - [ ] Total evaluations (COUNT user_evaluations)
  - [ ] Average meta score (AVG judge_meta_score)
  - [ ] Metrics performance:
    - Her metrik iÃ§in: avg primary_metric_gap, count
    - Trend hesapla (son 10 vs Ã¶nceki 10)
  - [ ] Improvement trend (overall)
  - [ ] Response format
- [ ] Database queries optimize et (indexes kullan)
- [ ] Test endpoint

---

### Task 4.13: CLI Testing Interface

**Tahmini SÃ¼re:** 3 saat

**YapÄ±lacaklar:**
- [ ] `backend/cli.py` oluÅŸtur:
  - [ ] `start_evaluation(primary_metric, use_pool)` â†’ API call
  - [ ] `submit_evaluation(response_id, evaluations)` â†’ API call
  - [ ] `get_feedback(evaluation_id)` â†’ API call
  - [ ] `get_stats()` â†’ API call
  - [ ] Pretty print results
- [ ] Interactive CLI (input prompts)
- [ ] Test CLI

---

### Task 4.14: End-to-End Test Suite

**Tahmini SÃ¼re:** 4 saat

**YapÄ±lacaklar:**
- [ ] `backend/tests/test_e2e.py` oluÅŸtur
- [ ] Test Scenario 1: Yeni soru Ã¼retme â†’ deÄŸerlendirme â†’ judge â†’ feedback
- [ ] Test Scenario 2: Havuzdan soru seÃ§me â†’ deÄŸerlendirme â†’ judge â†’ feedback
- [ ] Test Scenario 3: Tekrar eden hata (ChromaDB hafÄ±za)
- [ ] Test Scenario 4: Ä°statistikler
- [ ] Assert conditions:
  - [ ] Database records created
  - [ ] Judge meta score calculated
  - [ ] ChromaDB document added
  - [ ] Feedback returned
- [ ] Tests Ã§alÄ±ÅŸtÄ±r

---

### Task 4.15: Manual Testing Session

**Tahmini SÃ¼re:** 3 saat

**YapÄ±lacaklar:**
- [ ] Manuel test senaryolarÄ± Ã§alÄ±ÅŸtÄ±r (CLI kullanarak):
  1. [ ] **Ä°lk deÄŸerlendirme (Truthfulness):**
     - Soru Ã¼ret
     - Model cevaplasÄ±n
     - DeÄŸerlendirme yap (8 metrik)
     - Judge feedback al
     - Meta score kontrol et
  2. [ ] **Havuzdan seÃ§ (Safety):**
     - Havuzdan soru seÃ§
     - DeÄŸerlendirme yap
     - Feedback al
  3. [ ] **Tekrar eden hata:**
     - AynÄ± metrikte (Truthfulness) 3 farklÄ± deÄŸerlendirme yap
     - Her birinde biraz yumuÅŸak/sert deÄŸerlendir
     - 3. deÄŸerlendirmede judge'Ä±n "past patterns" referans ettiÄŸini kontrol et
  4. [ ] **Ä°statistikler:**
     - Stats endpoint Ã§aÄŸÄ±r
     - Metrics performance kontrol et
     - Improvement trend kontrol et
- [ ] LoglarÄ± incele (mentormind.log, errors.log, llm_calls.jsonl)
- [ ] Bug'larÄ± tespit et ve fix'le

---

### Task 4.16: Performance Testing

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] Judge duration Ã¶lÃ§ (Stage 1 + Stage 2)
- [ ] Database query performance kontrol et
- [ ] ChromaDB query latency Ã¶lÃ§
- [ ] Bottleneck'leri belirle
- [ ] Optimization notlarÄ± al (Phase 2 iÃ§in)

---

### Task 4.17: Documentation Update

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] README.md gÃ¼ncelle:
  - [ ] Installation instructions doÄŸru mu?
  - [ ] API endpoints listesi ekle
  - [ ] Example usage ekle (CLI)
- [ ] API documentation kontrol et (FastAPI auto-gen)
- [ ] Code comments ekle (missing parts)

---

### Task 4.18: Bug Fixes & Cleanup

**Tahmini SÃ¼re:** 3 saat

**YapÄ±lacaklar:**
- [ ] Tespit edilen bug'larÄ± fix'le
- [ ] Dead code sil
- [ ] Unused imports temizle
- [ ] Code formatting (black)
- [ ] Linting (flake8)
- [ ] Type hints ekle (mypy)

---

### Task 4.19: Final Verification

**Tahmini SÃ¼re:** 2 saat

**YapÄ±lacaklar:**
- [ ] TÃ¼m tests Ã§alÄ±ÅŸtÄ±r: `pytest`
- [ ] Coverage kontrol et (target: 80%+)
- [ ] Docker build: `docker-compose build`
- [ ] Docker run: `docker-compose up -d`
- [ ] Health check: All services healthy
- [ ] End-to-end workflow: BaÅŸtan sona Ã§alÄ±ÅŸÄ±yor mu?

---

### âœ… Week 4 Checklist

- [ ] ChromaDB entegrasyonu Ã§alÄ±ÅŸÄ±yor
- [ ] Judge Stage 2 (mentoring) Ã§alÄ±ÅŸÄ±yor
- [ ] Full judge workflow (Stage 1 + ChromaDB + Stage 2) Ã§alÄ±ÅŸÄ±yor
- [ ] Past mistakes judge'a hatÄ±rlatÄ±lÄ±yor
- [ ] Statistics API Ã§alÄ±ÅŸÄ±yor
- [ ] CLI testing interface hazÄ±r
- [ ] End-to-end tests geÃ§iyor
- [ ] Manual test senaryolarÄ± baÅŸarÄ±lÄ±
- [ ] Documentation gÃ¼ncel
- [ ] Code clean ve formatlanmÄ±ÅŸ

---

## ğŸ¯ Success Metrics

### Technical Metrics

- [ ] **Test Coverage:** 80%+ (backend)
- [ ] **API Response Time:** < 200ms (non-LLM endpoints)
- [ ] **Judge Duration:** 10-30 seconds (2-stage)
- [ ] **Database Queries:** Optimized (indexes kullanÄ±lÄ±yor)
- [ ] **Docker Build:** < 5 dakika
- [ ] **Container Startup:** < 30 saniye (all services)

### Functional Metrics

- [ ] **Question Generation:** 100% success rate
- [ ] **K Model Answers:** 4/4 model Ã§alÄ±ÅŸÄ±yor
- [ ] **User Evaluation:** Validation %100 doÄŸru
- [ ] **Judge Evaluation:** 2-stage workflow %100 baÅŸarÄ±lÄ±
- [ ] **ChromaDB Memory:** Past mistakes doÄŸru retrieve ediliyor
- [ ] **End-to-End:** Full workflow hiÃ§bir hata vermeden Ã§alÄ±ÅŸÄ±yor

### Quality Metrics

- [ ] **Code Quality:** Linting errors yok (flake8)
- [ ] **Code Format:** Black formatlanmÄ±ÅŸ
- [ ] **Type Hints:** Critical functions'larda mevcut
- [ ] **Documentation:** README + API docs gÃ¼ncel
- [ ] **Logging:** Comprehensive (3 log types)
- [ ] **Error Handling:** Try/except bloklarÄ± mevcut

---

## ğŸ‰ Phase 1 Completion

**Phase 1 tamamlandÄ±ÄŸÄ±nda elimizde ÅŸunlar olacak:**

âœ… **Ã‡alÄ±ÅŸan Backend API** (FastAPI)  
âœ… **5 Database Tablosu** (PostgreSQL)  
âœ… **Soru Ãœretimi** (Claude Sonnet 4.5)  
âœ… **4 K Model Entegrasyonu** (GPT-3.5, GPT-4o-mini, Claude Haiku, Gemini)  
âœ… **User Evaluation System**  
âœ… **2-Stage Judge System** (GPT-4o)  
âœ… **ChromaDB HafÄ±za**  
âœ… **Comprehensive Logging**  
âœ… **CLI Testing Interface**  
âœ… **Docker Infrastructure**  

**Sonraki adÄ±m:** Phase 2 - Frontend UI ğŸš€

---

**BaÅŸarÄ±lar!** ğŸ’ª